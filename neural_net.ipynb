{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch  \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Class and Training Functions\n",
    "Define Class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loaders():\n",
    "   # Import data\n",
    "    dir_X = '/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/Data/df_X_county.csv'\n",
    "    dir_y = '/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/Data/df_y_county.csv'\n",
    "    \n",
    "    X = pd.read_csv(dir_X)\n",
    "    X['constant'] = 1\n",
    "    y = pd.read_csv(dir_y)\n",
    "\n",
    "    # check if any nan values\n",
    "    nan_row_X = X[X.isna().any(axis=1)]\n",
    "    #print(nan_row_X)\n",
    "    nan_row_y = y[y.isna().any(axis=1)]\n",
    "    #print(nan_row_y)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    # split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # standardize X\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_model(nn_model, data_loaded, opt, batch_size=32):\n",
    "    \n",
    "    '''\n",
    "    Trains neural network model on X_train, y_train data.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    '''\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_train, X_eval, y_train, y_eval = data_loaded\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "    X_test_tensor = torch.tensor(X_eval)\n",
    "    y_test_tensor = torch.tensor(y_eval)\n",
    "    \n",
    "    nn_model.train()  # put model in train mode\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # train with (mini-batch) SGD; initialize optimizer\n",
    "    #opt = torch.optim.SGD(nn_model.parameters(), lr=1e-4)\n",
    "    n_samples, n_features = X_train_tensor.shape\n",
    "    # loop through data in batches\n",
    "\n",
    "    for batch_start in range(0, n_samples, batch_size):\n",
    "    # reset gradients to zero\n",
    "        opt.zero_grad()\n",
    "        # form batch\n",
    "        X_batch = X_train_tensor[batch_start:batch_start+batch_size]\n",
    "        y_batch = y_train_tensor[batch_start:batch_start+batch_size]\n",
    "        X_batch_test = X_test_tensor[batch_start:batch_start+batch_size]\n",
    "        y_batch_test = y_test_tensor[batch_start:batch_start+batch_size]\n",
    "        # pass batch through neural net to get prediction\n",
    "        y_pred = nn_model(X_batch.float())\n",
    "        y_pred = y_pred.unsqueeze(1)\n",
    "        y_pred_test = nn_model(X_batch_test.float())\n",
    "        y_pred_test = y_pred_test.unsqueeze(1)\n",
    "        # compute MSE loss\n",
    "        loss = mse_loss(y_pred, y_batch[:, None].float())\n",
    "        loss_test = mse_loss(y_pred_test, y_batch_test[:, None].float())\n",
    "        # back-propagate loss\n",
    "        loss.backward()\n",
    "        # update model parameters based on backpropogated gradients\n",
    "        opt.step()\n",
    "        \n",
    "        #print(f\"Mean Train MSE: {epoch_loss}\")\n",
    "        \n",
    "    return epoch_loss, epoch_loss_test\n",
    "\n",
    "def evaluate_model(nn_model, X_eval, y_eval, batch_size=32):\n",
    "    '''\n",
    "    Evaluates trained neural network model on X_eval, y_eval data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    X_eval: np.array\n",
    "        matrix of training data features\n",
    "    y_eval: np.array\n",
    "        vector of training data labels\n",
    "    batch_size: int\n",
    "        batch size to looping over dataset to generate predictions\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse: float\n",
    "        MSE of trained model on X_eval, y_eval data\n",
    "    '''\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_eval_tensor = torch.tensor(X_eval)\n",
    "    y_eval_tensor = torch.tensor(y_eval)\n",
    "    n_samples = X_eval_tensor.shape[0]\n",
    "    nn_model.eval() # put in eval mode\n",
    "    # loop over data and generate predictions\n",
    "    preds = []\n",
    "    for batch_start in range(0, n_samples, batch_size):\n",
    "        # form batch\n",
    "        X_batch = X_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        y_batch = y_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        with torch.no_grad():  # no need to compute gradients during evaluation\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            preds.append(y_pred)\n",
    "    # compute MSE across all samples\n",
    "    all_preds = torch.cat(preds)\n",
    "    loss = mse_loss(all_preds, y_eval_tensor[:, None].float()).item()\n",
    "    return loss\n",
    "\n",
    "def train_and_validate(config):\n",
    "\n",
    "    '''Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        matrix of training data features\n",
    "    y_train: np.array\n",
    "        vector of training data labels\n",
    "    max_iter: int\n",
    "        maximum number of iterations to train for\n",
    "    batch_size: int\n",
    "        batch size to use when training w/ SGD\n",
    "    '''\n",
    "    # intialize neural network\n",
    "    data_loaded = data_loaders()\n",
    "    X_train, X_eval, y_train, y_eval = data_loaded\n",
    "    print(y_eval)\n",
    "    n_samples, n_features = X_train.shape\n",
    "    nn_model = NN_configureable(n_features, config[\"n_hidden_dim\"], config[\"n_layers\"])\n",
    "\n",
    "    opt = torch.optim.SGD(nn_model.parameters(), lr=config[\"lr\"],  momentum=0.9)\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    max_iter = config[\"train_iterations\"]\n",
    "\n",
    "    # Start the training.\n",
    "    for it in range(max_iter):\n",
    "        # save losses across all batches\n",
    "        train_epoch_loss, test_epoch_loss = train_model(nn_model, data_loaded, opt, batch_size)\n",
    "        valid_epoch_loss = evaluate_model(nn_model, X_eval, y_eval, batch_size)\n",
    "\n",
    "    with tune.checkpoint_dir(it) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "            torch.save((nn_model.state_dict(), opt.state_dict()), path)\n",
    "    tune.report(\n",
    "        loss=valid_epoch_loss)\n",
    "\n",
    "class NN(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            # Network has a single hidden layer\n",
    "            # Apply ReLU activation in between the hidden layer and output node\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NN_configureable(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        print(input_dim)\n",
    "        self.hidden_layers = hidden_layers\n",
    "        #self.layers = nn.ModuleDict()\n",
    "        self.layers = nn.ModuleDict()\n",
    "        \n",
    "        # Define input layer\n",
    "        self.layers[\"input\"] = nn.Linear(in_features = input_dim, out_features = hidden_dim)\n",
    "        # Define hidden layers\n",
    "        for i in range(self.hidden_layers):\n",
    "            self.layers[f\"hidden_{i}\"] = nn.Linear(in_features = hidden_dim, out_features = hidden_dim)\n",
    "        # Define output layer\n",
    "        self.layers[\"output\"] = nn.Linear(in_features = hidden_dim, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers[\"input\"](x)\n",
    "        for i in range(self.hidden_layers):\n",
    "            x = F.relu(self.layers[f\"hidden_{i}\"](x))\n",
    "\n",
    "        return self.layers[\"output\"](x)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Function for Ray Tune\n",
    "Hyperparameter search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Import combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():   \n",
    "    \n",
    "    # Search Function for Ray Tune - Hyperparameter search\n",
    "     \n",
    "    #X = pd.read_csv('./Data/df_X_county.csv')\n",
    "    #print(X.head)\n",
    "     \n",
    "    # Define the parameter search configuration.\n",
    "    config = {\n",
    "        \"n_layers\": \n",
    "            #tune.sample_from(lambda _: 2 ** np.random.randint(1, 5)),\n",
    "            tune.grid_search([1, 2, 3]),\n",
    "        \"n_hidden_dim\": \n",
    "            #tune.sample_from(lambda _: 2 ** np.random.randint(4, 8)),\n",
    "            tune.grid_search([1, 2]),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([32]),\n",
    "        \"train_iterations\": tune.choice([50, 100])\n",
    "    }\n",
    "\n",
    "    max_num_iter = 50\n",
    "    grace_period = 1\n",
    "    # Number of Ray Tune random search experiments to run.\n",
    "    num_samples = 20\n",
    "    \n",
    "    # Schduler to stop bad performing trails.\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t = max_num_iter,\n",
    "        grace_period = grace_period,\n",
    "        reduction_factor = 2 \n",
    "    )\n",
    "\n",
    "    # Reporter to show on command line/output window\n",
    "    reporter = CLIReporter(\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "\n",
    "    #nn_model_place = NN_configureable(input_dim, config[\"n_hidden_dim\"], config[\"n_layers\"])\n",
    "\n",
    "    # Start Ray Tune search\n",
    "    result = tune.run(\n",
    "        train_and_validate,\n",
    "        resources_per_trial = {\"cpu\": 2, \"gpu\": 0},\n",
    "        config = config,\n",
    "        num_samples = num_samples,\n",
    "        scheduler = scheduler,\n",
    "        local_dir = '../outputs/raytune_result',\n",
    "        keep_checkpoints_num = 1,\n",
    "        checkpoint_score_attr = 'min-validation_loss',\n",
    "        progress_reporter = reporter\n",
    "    )\n",
    "\n",
    "    # Extract the best trial run from the search.\n",
    "    best_trial = result.get_best_trial(\n",
    "        'loss', 'min', 'last'\n",
    "    )\n",
    "    print(f\"Best trial config: {best_trial.config}\")\n",
    "    print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "    \n",
    "    #n_layers = np.arange(1, 5) # iterate through hidden layer count\n",
    "    #n_hidden_dim = np.arange(8, 65, 8)  # iterate through hidden layer node count\n",
    "    #mse_dict = {}\n",
    "    \n",
    "    #for i in range(len(n_layers)):\n",
    "    #    for j in range(len(n_hidden_dim)):\n",
    "    #        tuple_place = (i, j)\n",
    "    #        nn_model_place = NN_configureable(input_dim, hidden_dim = j, hidden_layers = i)\n",
    "    #        nn_model_result = train_model(nn_model_place, X_train, y_train, X_test, y_test, 32)\n",
    "    #        train_mse =  evaluate_model(nn_model_result[0], X_train, y_train)\n",
    "    #        test_mse = evaluate_model(nn_model_result[0], X_test, y_test)\n",
    "    #        #print(tuple_place)\n",
    "    #        train_test_list = [train_mse, test_mse]\n",
    "    #        mse_dict[tuple_place] = train_test_list\n",
    "            \n",
    "        \n",
    "        \n",
    "    #nn_model_place = NN_configureable(input_dim, 8, 2)\n",
    "    #nn_model_place = NN(input_dim, 8)\n",
    "    #nn_model_result = train_model(nn_model_place, X_train, y_train, X_test, y_test, 32)\n",
    "    #train_mse = evaluate_model(nn_model_result[0], X_train, y_train)\n",
    "    #test_mse = evaluate_model(nn_model_result[0], X_test, y_test)\n",
    "        \n",
    "    #for key in mse_dict:\n",
    "    #    print(f\"Train MSE for model: hidden_layers = {key[0]}, hidden_dim = {key[1]} is: {mse_dict[key][0]}\")\n",
    "    #    print(f\"Test MSE for model: hidden_layers = {key[0]}, hidden_dim = {key[1]} is: {mse_dict[key][1]}\")\n",
    "\n",
    "    # plot the model's test errors\n",
    "    #plt.plot(range(len(nn_model_result[1])), nn_model_result[1])\n",
    "    # axis labels\n",
    "\n",
    "    '''\n",
    "    plt.xlabel('Iteration Step')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.title(\"Model 1 - Hidden Layer - ReLU\")\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:47:53,789\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:47:53 (running for 00:00:00.06)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 16/120 (15 PENDING, 1 RUNNING)\n",
      "+--------------------------------+----------+-----------------+--------------+-------------+----------------+------------+--------------------+\n",
      "| Trial name                     | status   | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |\n",
      "|--------------------------------+----------+-----------------+--------------+-------------+----------------+------------+--------------------|\n",
      "| train_and_validate_ef910_00000 | RUNNING  | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |\n",
      "| train_and_validate_ef910_00001 | PENDING  |                 |           32 | 0.000646454 |              2 |          1 |                 50 |\n",
      "| train_and_validate_ef910_00002 | PENDING  |                 |           32 | 0.00232123  |              1 |          2 |                 50 |\n",
      "| train_and_validate_ef910_00003 | PENDING  |                 |           32 | 0.000441908 |              2 |          2 |                 50 |\n",
      "| train_and_validate_ef910_00004 | PENDING  |                 |           32 | 0.000388301 |              1 |          3 |                 50 |\n",
      "| train_and_validate_ef910_00005 | PENDING  |                 |           32 | 0.00265981  |              2 |          3 |                100 |\n",
      "| train_and_validate_ef910_00006 | PENDING  |                 |           32 | 0.0160185   |              1 |          1 |                 50 |\n",
      "| train_and_validate_ef910_00007 | PENDING  |                 |           32 | 0.000957223 |              2 |          1 |                100 |\n",
      "| train_and_validate_ef910_00008 | PENDING  |                 |           32 | 0.00710632  |              1 |          2 |                 50 |\n",
      "| train_and_validate_ef910_00009 | PENDING  |                 |           32 | 0.000175338 |              2 |          2 |                100 |\n",
      "| train_and_validate_ef910_00010 | PENDING  |                 |           32 | 0.000121385 |              1 |          3 |                 50 |\n",
      "| train_and_validate_ef910_00011 | PENDING  |                 |           32 | 0.0396404   |              2 |          3 |                 50 |\n",
      "| train_and_validate_ef910_00012 | PENDING  |                 |           32 | 0.00416303  |              1 |          1 |                100 |\n",
      "| train_and_validate_ef910_00013 | PENDING  |                 |           32 | 0.000609101 |              2 |          1 |                 50 |\n",
      "| train_and_validate_ef910_00014 | PENDING  |                 |           32 | 0.000508702 |              1 |          2 |                100 |\n",
      "| train_and_validate_ef910_00015 | PENDING  |                 |           32 | 0.0146762   |              2 |          2 |                 50 |\n",
      "+--------------------------------+----------+-----------------+--------------+-------------+----------------+------------+--------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76367)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 17687x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m 13\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 106386.5625\u001b[32m [repeated 19065x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>date               </th><th>done  </th><th>experiment_tag                                                            </th><th>hostname                     </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">         loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_and_validate_ef910_00000</td><td>2023-05-10_16-47-59</td><td>True  </td><td>0_batch_size=32,lr=0.0004,n_hidden_dim=1,n_layers=1,train_iterations=50   </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.1161e+06 </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             4.16121</td><td style=\"text-align: right;\">           4.16121</td><td style=\"text-align: right;\">       4.16121</td><td style=\"text-align: right;\"> 1683751679</td><td style=\"text-align: right;\">                   1</td><td>ef910_00000</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00001</td><td>2023-05-10_16-48-01</td><td>True  </td><td>1_batch_size=32,lr=0.0006,n_hidden_dim=2,n_layers=1,train_iterations=50   </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.21764</td><td style=\"text-align: right;\">           4.21764</td><td style=\"text-align: right;\">       4.21764</td><td style=\"text-align: right;\"> 1683751681</td><td style=\"text-align: right;\">                   1</td><td>ef910_00001</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00002</td><td>2023-05-10_16-48-02</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11739e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.1529 </td><td style=\"text-align: right;\">           5.1529 </td><td style=\"text-align: right;\">       5.1529 </td><td style=\"text-align: right;\"> 1683751682</td><td style=\"text-align: right;\">                   1</td><td>ef910_00002</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00003</td><td>2023-05-10_16-48-02</td><td>True  </td><td>3_batch_size=32,lr=0.0004,n_hidden_dim=2,n_layers=2,train_iterations=50   </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11607e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.22721</td><td style=\"text-align: right;\">           5.22721</td><td style=\"text-align: right;\">       5.22721</td><td style=\"text-align: right;\"> 1683751682</td><td style=\"text-align: right;\">                   1</td><td>ef910_00003</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00004</td><td>2023-05-10_16-48-05</td><td>True  </td><td>4_batch_size=32,lr=0.0004,n_hidden_dim=1,n_layers=3,train_iterations=50   </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11609e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.77656</td><td style=\"text-align: right;\">           5.77656</td><td style=\"text-align: right;\">       5.77656</td><td style=\"text-align: right;\"> 1683751685</td><td style=\"text-align: right;\">                   1</td><td>ef910_00004</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00005</td><td>2023-05-10_16-48-13</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11784e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">            11.6102 </td><td style=\"text-align: right;\">          11.6102 </td><td style=\"text-align: right;\">      11.6102 </td><td style=\"text-align: right;\"> 1683751693</td><td style=\"text-align: right;\">                   1</td><td>ef910_00005</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00006</td><td>2023-05-10_16-48-06</td><td>True  </td><td>6_batch_size=32,lr=0.0160,n_hidden_dim=1,n_layers=1,train_iterations=50   </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             4.20862</td><td style=\"text-align: right;\">           4.20862</td><td style=\"text-align: right;\">       4.20862</td><td style=\"text-align: right;\"> 1683751686</td><td style=\"text-align: right;\">                   1</td><td>ef910_00006</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00007</td><td>2023-05-10_16-48-10</td><td>True  </td><td>7_batch_size=32,lr=0.0010,n_hidden_dim=2,n_layers=1,train_iterations=100  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             8.38895</td><td style=\"text-align: right;\">           8.38895</td><td style=\"text-align: right;\">       8.38895</td><td style=\"text-align: right;\"> 1683751690</td><td style=\"text-align: right;\">                   1</td><td>ef910_00007</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00008</td><td>2023-05-10_16-48-10</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11713e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             4.82228</td><td style=\"text-align: right;\">           4.82228</td><td style=\"text-align: right;\">       4.82228</td><td style=\"text-align: right;\"> 1683751690</td><td style=\"text-align: right;\">                   1</td><td>ef910_00008</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00009</td><td>2023-05-10_16-48-16</td><td>True  </td><td>9_batch_size=32,lr=0.0002,n_hidden_dim=2,n_layers=2,train_iterations=100  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11613e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            10.3066 </td><td style=\"text-align: right;\">          10.3066 </td><td style=\"text-align: right;\">      10.3066 </td><td style=\"text-align: right;\"> 1683751696</td><td style=\"text-align: right;\">                   1</td><td>ef910_00009</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00010</td><td>2023-05-10_16-48-16</td><td>True  </td><td>10_batch_size=32,lr=0.0001,n_hidden_dim=1,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.64628</td><td style=\"text-align: right;\">           5.64628</td><td style=\"text-align: right;\">       5.64628</td><td style=\"text-align: right;\"> 1683751696</td><td style=\"text-align: right;\">                   1</td><td>ef910_00010</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00011</td><td>2023-05-10_16-48-16</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.14115e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.94448</td><td style=\"text-align: right;\">           5.94448</td><td style=\"text-align: right;\">       5.94448</td><td style=\"text-align: right;\"> 1683751696</td><td style=\"text-align: right;\">                   1</td><td>ef910_00011</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00012</td><td>2023-05-10_16-48-21</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11859e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             8.26868</td><td style=\"text-align: right;\">           8.26868</td><td style=\"text-align: right;\">       8.26868</td><td style=\"text-align: right;\"> 1683751701</td><td style=\"text-align: right;\">                   1</td><td>ef910_00012</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00013</td><td>2023-05-10_16-48-20</td><td>True  </td><td>13_batch_size=32,lr=0.0006,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             4.14188</td><td style=\"text-align: right;\">           4.14188</td><td style=\"text-align: right;\">       4.14188</td><td style=\"text-align: right;\"> 1683751700</td><td style=\"text-align: right;\">                   1</td><td>ef910_00013</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00014</td><td>2023-05-10_16-48-26</td><td>True  </td><td>14_batch_size=32,lr=0.0005,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11604e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            10.0625 </td><td style=\"text-align: right;\">          10.0625 </td><td style=\"text-align: right;\">      10.0625 </td><td style=\"text-align: right;\"> 1683751706</td><td style=\"text-align: right;\">                   1</td><td>ef910_00014</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00015</td><td>2023-05-10_16-48-22</td><td>True  </td><td>15_batch_size=32,lr=0.0147,n_hidden_dim=2,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.15141</td><td style=\"text-align: right;\">           5.15141</td><td style=\"text-align: right;\">       5.15141</td><td style=\"text-align: right;\"> 1683751702</td><td style=\"text-align: right;\">                   1</td><td>ef910_00015</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00016</td><td>2023-05-10_16-48-31</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11756e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            11.3381 </td><td style=\"text-align: right;\">          11.3381 </td><td style=\"text-align: right;\">      11.3381 </td><td style=\"text-align: right;\"> 1683751711</td><td style=\"text-align: right;\">                   1</td><td>ef910_00016</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00017</td><td>2023-05-10_16-48-27</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11861e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.91535</td><td style=\"text-align: right;\">           5.91535</td><td style=\"text-align: right;\">       5.91535</td><td style=\"text-align: right;\"> 1683751707</td><td style=\"text-align: right;\">                   1</td><td>ef910_00017</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00018</td><td>2023-05-10_16-48-30</td><td>True  </td><td>18_batch_size=32,lr=0.0015,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             8.52014</td><td style=\"text-align: right;\">           8.52014</td><td style=\"text-align: right;\">       8.52014</td><td style=\"text-align: right;\"> 1683751710</td><td style=\"text-align: right;\">                   1</td><td>ef910_00018</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00019</td><td>2023-05-10_16-48-35</td><td>True  </td><td>19_batch_size=32,lr=0.0003,n_hidden_dim=2,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             8.4509 </td><td style=\"text-align: right;\">           8.4509 </td><td style=\"text-align: right;\">       8.4509 </td><td style=\"text-align: right;\"> 1683751715</td><td style=\"text-align: right;\">                   1</td><td>ef910_00019</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00020</td><td>2023-05-10_16-48-32</td><td>True  </td><td>20_batch_size=32,lr=0.0021,n_hidden_dim=1,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11709e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.88937</td><td style=\"text-align: right;\">           4.88937</td><td style=\"text-align: right;\">       4.88937</td><td style=\"text-align: right;\"> 1683751712</td><td style=\"text-align: right;\">                   1</td><td>ef910_00020</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00021</td><td>2023-05-10_16-48-35</td><td>True  </td><td>21_batch_size=32,lr=0.0017,n_hidden_dim=2,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.1164e+06 </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.2604 </td><td style=\"text-align: right;\">           5.2604 </td><td style=\"text-align: right;\">       5.2604 </td><td style=\"text-align: right;\"> 1683751715</td><td style=\"text-align: right;\">                   1</td><td>ef910_00021</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00022</td><td>2023-05-10_16-48-43</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.15961e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            11.3206 </td><td style=\"text-align: right;\">          11.3206 </td><td style=\"text-align: right;\">      11.3206 </td><td style=\"text-align: right;\"> 1683751723</td><td style=\"text-align: right;\">                   1</td><td>ef910_00022</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00023</td><td>2023-05-10_16-48-38</td><td>True  </td><td>23_batch_size=32,lr=0.0238,n_hidden_dim=2,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11658e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.89965</td><td style=\"text-align: right;\">           5.89965</td><td style=\"text-align: right;\">       5.89965</td><td style=\"text-align: right;\"> 1683751718</td><td style=\"text-align: right;\">                   1</td><td>ef910_00023</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00024</td><td>2023-05-10_16-48-43</td><td>True  </td><td>24_batch_size=32,lr=0.0001,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             8.30806</td><td style=\"text-align: right;\">           8.30806</td><td style=\"text-align: right;\">       8.30806</td><td style=\"text-align: right;\"> 1683751723</td><td style=\"text-align: right;\">                   1</td><td>ef910_00024</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00025</td><td>2023-05-10_16-48-40</td><td>True  </td><td>25_batch_size=32,lr=0.0492,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             4.30433</td><td style=\"text-align: right;\">           4.30433</td><td style=\"text-align: right;\">       4.30433</td><td style=\"text-align: right;\"> 1683751720</td><td style=\"text-align: right;\">                   1</td><td>ef910_00025</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00026</td><td>2023-05-10_16-48-48</td><td>True  </td><td>26_batch_size=32,lr=0.0001,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             9.86797</td><td style=\"text-align: right;\">           9.86797</td><td style=\"text-align: right;\">       9.86797</td><td style=\"text-align: right;\"> 1683751728</td><td style=\"text-align: right;\">                   1</td><td>ef910_00026</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00027</td><td>2023-05-10_16-48-45</td><td>True  </td><td>27_batch_size=32,lr=0.0004,n_hidden_dim=2,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11608e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.26223</td><td style=\"text-align: right;\">           5.26223</td><td style=\"text-align: right;\">       5.26223</td><td style=\"text-align: right;\"> 1683751725</td><td style=\"text-align: right;\">                   1</td><td>ef910_00027</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00028</td><td>2023-05-10_16-48-54</td><td>True  </td><td>28_batch_size=32,lr=0.0006,n_hidden_dim=1,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.116e+06  </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            11.4529 </td><td style=\"text-align: right;\">          11.4529 </td><td style=\"text-align: right;\">      11.4529 </td><td style=\"text-align: right;\"> 1683751734</td><td style=\"text-align: right;\">                   1</td><td>ef910_00028</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00029</td><td>2023-05-10_16-48-55</td><td>True  </td><td>29_batch_size=32,lr=0.0014,n_hidden_dim=2,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11609e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            11.9261 </td><td style=\"text-align: right;\">          11.9261 </td><td style=\"text-align: right;\">      11.9261 </td><td style=\"text-align: right;\"> 1683751735</td><td style=\"text-align: right;\">                   1</td><td>ef910_00029</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00030</td><td>2023-05-10_16-48-54</td><td>True  </td><td>30_batch_size=32,lr=0.0015,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             8.43437</td><td style=\"text-align: right;\">           8.43437</td><td style=\"text-align: right;\">       8.43437</td><td style=\"text-align: right;\"> 1683751734</td><td style=\"text-align: right;\">                   1</td><td>ef910_00030</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00031</td><td>2023-05-10_16-48-52</td><td>True  </td><td>31_batch_size=32,lr=0.0821,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.1306 </td><td style=\"text-align: right;\">           4.1306 </td><td style=\"text-align: right;\">       4.1306 </td><td style=\"text-align: right;\"> 1683751732</td><td style=\"text-align: right;\">                   1</td><td>ef910_00031</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00032</td><td>2023-05-10_16-48-57</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.19694e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.01035</td><td style=\"text-align: right;\">           5.01035</td><td style=\"text-align: right;\">       5.01035</td><td style=\"text-align: right;\"> 1683751737</td><td style=\"text-align: right;\">                   1</td><td>ef910_00032</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00033</td><td>2023-05-10_16-48-59</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.17626e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.31764</td><td style=\"text-align: right;\">           5.31764</td><td style=\"text-align: right;\">       5.31764</td><td style=\"text-align: right;\"> 1683751739</td><td style=\"text-align: right;\">                   1</td><td>ef910_00033</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00034</td><td>2023-05-10_16-49-00</td><td>True  </td><td>34_batch_size=32,lr=0.0003,n_hidden_dim=1,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11613e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.78861</td><td style=\"text-align: right;\">           5.78861</td><td style=\"text-align: right;\">       5.78861</td><td style=\"text-align: right;\"> 1683751740</td><td style=\"text-align: right;\">                   1</td><td>ef910_00034</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00035</td><td>2023-05-10_16-49-08</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11861e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            12.123  </td><td style=\"text-align: right;\">          12.123  </td><td style=\"text-align: right;\">      12.123  </td><td style=\"text-align: right;\"> 1683751748</td><td style=\"text-align: right;\">                   1</td><td>ef910_00035</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00036</td><td>2023-05-10_16-49-05</td><td>True  </td><td>36_batch_size=32,lr=0.0007,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             8.35341</td><td style=\"text-align: right;\">           8.35341</td><td style=\"text-align: right;\">       8.35341</td><td style=\"text-align: right;\"> 1683751745</td><td style=\"text-align: right;\">                   1</td><td>ef910_00036</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00037</td><td>2023-05-10_16-49-04</td><td>True  </td><td>37_batch_size=32,lr=0.0025,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             4.39199</td><td style=\"text-align: right;\">           4.39199</td><td style=\"text-align: right;\">       4.39199</td><td style=\"text-align: right;\"> 1683751744</td><td style=\"text-align: right;\">                   1</td><td>ef910_00037</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00038</td><td>2023-05-10_16-49-10</td><td>True  </td><td>38_batch_size=32,lr=0.0169,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11655e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             9.82303</td><td style=\"text-align: right;\">           9.82303</td><td style=\"text-align: right;\">       9.82303</td><td style=\"text-align: right;\"> 1683751750</td><td style=\"text-align: right;\">                   1</td><td>ef910_00038</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00039</td><td>2023-05-10_16-49-14</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11861e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            10.4229 </td><td style=\"text-align: right;\">          10.4229 </td><td style=\"text-align: right;\">      10.4229 </td><td style=\"text-align: right;\"> 1683751754</td><td style=\"text-align: right;\">                   1</td><td>ef910_00039</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00040</td><td>2023-05-10_16-49-11</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.19759e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.76305</td><td style=\"text-align: right;\">           5.76305</td><td style=\"text-align: right;\">       5.76305</td><td style=\"text-align: right;\"> 1683751751</td><td style=\"text-align: right;\">                   1</td><td>ef910_00040</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00041</td><td>2023-05-10_16-49-13</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11688e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.92872</td><td style=\"text-align: right;\">           5.92872</td><td style=\"text-align: right;\">       5.92872</td><td style=\"text-align: right;\"> 1683751753</td><td style=\"text-align: right;\">                   1</td><td>ef910_00041</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00042</td><td>2023-05-10_16-49-18</td><td>True  </td><td>42_batch_size=32,lr=0.0001,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             8.1288 </td><td style=\"text-align: right;\">           8.1288 </td><td style=\"text-align: right;\">       8.1288 </td><td style=\"text-align: right;\"> 1683751758</td><td style=\"text-align: right;\">                   1</td><td>ef910_00042</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00043</td><td>2023-05-10_16-49-15</td><td>True  </td><td>43_batch_size=32,lr=0.0003,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.15008</td><td style=\"text-align: right;\">           4.15008</td><td style=\"text-align: right;\">       4.15008</td><td style=\"text-align: right;\"> 1683751755</td><td style=\"text-align: right;\">                   1</td><td>ef910_00043</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00044</td><td>2023-05-10_16-49-24</td><td>True  </td><td>44_batch_size=32,lr=0.0129,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11625e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             9.96451</td><td style=\"text-align: right;\">           9.96451</td><td style=\"text-align: right;\">       9.96451</td><td style=\"text-align: right;\"> 1683751764</td><td style=\"text-align: right;\">                   1</td><td>ef910_00044</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00045</td><td>2023-05-10_16-49-25</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11748e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            10.4848 </td><td style=\"text-align: right;\">          10.4848 </td><td style=\"text-align: right;\">      10.4848 </td><td style=\"text-align: right;\"> 1683751765</td><td style=\"text-align: right;\">                   1</td><td>ef910_00045</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00046</td><td>2023-05-10_16-49-21</td><td>True  </td><td>46_batch_size=32,lr=0.0003,n_hidden_dim=1,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.74805</td><td style=\"text-align: right;\">           5.74805</td><td style=\"text-align: right;\">       5.74805</td><td style=\"text-align: right;\"> 1683751761</td><td style=\"text-align: right;\">                   1</td><td>ef910_00046</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00047</td><td>2023-05-10_16-49-24</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11703e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.80644</td><td style=\"text-align: right;\">           5.80644</td><td style=\"text-align: right;\">       5.80644</td><td style=\"text-align: right;\"> 1683751764</td><td style=\"text-align: right;\">                   1</td><td>ef910_00047</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00048</td><td>2023-05-10_16-49-25</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11881e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.08209</td><td style=\"text-align: right;\">           4.08209</td><td style=\"text-align: right;\">       4.08209</td><td style=\"text-align: right;\"> 1683751765</td><td style=\"text-align: right;\">                   1</td><td>ef910_00048</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00049</td><td>2023-05-10_16-49-28</td><td>True  </td><td>49_batch_size=32,lr=0.0162,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             4.25537</td><td style=\"text-align: right;\">           4.25537</td><td style=\"text-align: right;\">       4.25537</td><td style=\"text-align: right;\"> 1683751768</td><td style=\"text-align: right;\">                   1</td><td>ef910_00049</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00050</td><td>2023-05-10_16-49-34</td><td>True  </td><td>50_batch_size=32,lr=0.0006,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11599e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             9.7271 </td><td style=\"text-align: right;\">           9.7271 </td><td style=\"text-align: right;\">       9.7271 </td><td style=\"text-align: right;\"> 1683751774</td><td style=\"text-align: right;\">                   1</td><td>ef910_00050</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00051</td><td>2023-05-10_16-49-30</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.12365e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.16652</td><td style=\"text-align: right;\">           5.16652</td><td style=\"text-align: right;\">       5.16652</td><td style=\"text-align: right;\"> 1683751770</td><td style=\"text-align: right;\">                   1</td><td>ef910_00051</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00052</td><td>2023-05-10_16-49-37</td><td>True  </td><td>52_batch_size=32,lr=0.0004,n_hidden_dim=1,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11608e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">            11.6976 </td><td style=\"text-align: right;\">          11.6976 </td><td style=\"text-align: right;\">      11.6976 </td><td style=\"text-align: right;\"> 1683751777</td><td style=\"text-align: right;\">                   1</td><td>ef910_00052</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00053</td><td>2023-05-10_16-49-40</td><td>True  </td><td>53_batch_size=32,lr=0.0006,n_hidden_dim=2,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11597e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            12.0878 </td><td style=\"text-align: right;\">          12.0878 </td><td style=\"text-align: right;\">      12.0878 </td><td style=\"text-align: right;\"> 1683751780</td><td style=\"text-align: right;\">                   1</td><td>ef910_00053</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00054</td><td>2023-05-10_16-49-39</td><td>True  </td><td>54_batch_size=32,lr=0.0019,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             8.66859</td><td style=\"text-align: right;\">           8.66859</td><td style=\"text-align: right;\">       8.66859</td><td style=\"text-align: right;\"> 1683751779</td><td style=\"text-align: right;\">                   1</td><td>ef910_00054</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00055</td><td>2023-05-10_16-49-42</td><td>True  </td><td>55_batch_size=32,lr=0.0015,n_hidden_dim=2,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             8.15336</td><td style=\"text-align: right;\">           8.15336</td><td style=\"text-align: right;\">       8.15336</td><td style=\"text-align: right;\"> 1683751782</td><td style=\"text-align: right;\">                   1</td><td>ef910_00055</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00056</td><td>2023-05-10_16-49-47</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11697e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             9.94701</td><td style=\"text-align: right;\">           9.94701</td><td style=\"text-align: right;\">       9.94701</td><td style=\"text-align: right;\"> 1683751787</td><td style=\"text-align: right;\">                   1</td><td>ef910_00056</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00057</td><td>2023-05-10_16-49-49</td><td>True  </td><td>57_batch_size=32,lr=0.0002,n_hidden_dim=2,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11613e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            10.3834 </td><td style=\"text-align: right;\">          10.3834 </td><td style=\"text-align: right;\">      10.3834 </td><td style=\"text-align: right;\"> 1683751789</td><td style=\"text-align: right;\">                   1</td><td>ef910_00057</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00058</td><td>2023-05-10_16-49-46</td><td>True  </td><td>58_batch_size=32,lr=0.0153,n_hidden_dim=1,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11641e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.84998</td><td style=\"text-align: right;\">           5.84998</td><td style=\"text-align: right;\">       5.84998</td><td style=\"text-align: right;\"> 1683751786</td><td style=\"text-align: right;\">                   1</td><td>ef910_00058</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00059</td><td>2023-05-10_16-49-54</td><td>True  </td><td>59_batch_size=32,lr=0.0004,n_hidden_dim=2,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11608e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            11.5749 </td><td style=\"text-align: right;\">          11.5749 </td><td style=\"text-align: right;\">      11.5749 </td><td style=\"text-align: right;\"> 1683751794</td><td style=\"text-align: right;\">                   1</td><td>ef910_00059</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00060</td><td>2023-05-10_16-49-54</td><td>True  </td><td>60_batch_size=32,lr=0.0680,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             8.41152</td><td style=\"text-align: right;\">           8.41152</td><td style=\"text-align: right;\">       8.41152</td><td style=\"text-align: right;\"> 1683751794</td><td style=\"text-align: right;\">                   1</td><td>ef910_00060</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00061</td><td>2023-05-10_16-49-56</td><td>True  </td><td>61_batch_size=32,lr=0.0015,n_hidden_dim=2,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             8.37587</td><td style=\"text-align: right;\">           8.37587</td><td style=\"text-align: right;\">       8.37587</td><td style=\"text-align: right;\"> 1683751796</td><td style=\"text-align: right;\">                   1</td><td>ef910_00061</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00062</td><td>2023-05-10_16-49-59</td><td>True  </td><td>62_batch_size=32,lr=0.0011,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.1159e+06 </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            10.3692 </td><td style=\"text-align: right;\">          10.3692 </td><td style=\"text-align: right;\">      10.3692 </td><td style=\"text-align: right;\"> 1683751799</td><td style=\"text-align: right;\">                   1</td><td>ef910_00062</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00063</td><td>2023-05-10_16-50-04</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11708e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            10.1813 </td><td style=\"text-align: right;\">          10.1813 </td><td style=\"text-align: right;\">      10.1813 </td><td style=\"text-align: right;\"> 1683751804</td><td style=\"text-align: right;\">                   1</td><td>ef910_00063</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00064</td><td>2023-05-10_16-50-01</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.20382e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             6.15983</td><td style=\"text-align: right;\">           6.15983</td><td style=\"text-align: right;\">       6.15983</td><td style=\"text-align: right;\"> 1683751801</td><td style=\"text-align: right;\">                   1</td><td>ef910_00064</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00065</td><td>2023-05-10_16-50-08</td><td>True  </td><td>65_batch_size=32,lr=0.0013,n_hidden_dim=2,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11599e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">            12.0211 </td><td style=\"text-align: right;\">          12.0211 </td><td style=\"text-align: right;\">      12.0211 </td><td style=\"text-align: right;\"> 1683751808</td><td style=\"text-align: right;\">                   1</td><td>ef910_00065</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00066</td><td>2023-05-10_16-50-08</td><td>True  </td><td>66_batch_size=32,lr=0.0008,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             8.58905</td><td style=\"text-align: right;\">           8.58905</td><td style=\"text-align: right;\">       8.58905</td><td style=\"text-align: right;\"> 1683751808</td><td style=\"text-align: right;\">                   1</td><td>ef910_00066</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00067</td><td>2023-05-10_16-50-05</td><td>True  </td><td>67_batch_size=32,lr=0.0626,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             4.26332</td><td style=\"text-align: right;\">           4.26332</td><td style=\"text-align: right;\">       4.26332</td><td style=\"text-align: right;\"> 1683751805</td><td style=\"text-align: right;\">                   1</td><td>ef910_00067</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00068</td><td>2023-05-10_16-50-09</td><td>True  </td><td>68_batch_size=32,lr=0.0004,n_hidden_dim=1,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.1161e+06 </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.09598</td><td style=\"text-align: right;\">           5.09598</td><td style=\"text-align: right;\">       5.09598</td><td style=\"text-align: right;\"> 1683751809</td><td style=\"text-align: right;\">                   1</td><td>ef910_00068</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00069</td><td>2023-05-10_16-50-11</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11785e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.47614</td><td style=\"text-align: right;\">           5.47614</td><td style=\"text-align: right;\">       5.47614</td><td style=\"text-align: right;\"> 1683751811</td><td style=\"text-align: right;\">                   1</td><td>ef910_00069</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00070</td><td>2023-05-10_16-50-20</td><td>True  </td><td>70_batch_size=32,lr=0.0125,n_hidden_dim=1,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11624e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">            12.0183 </td><td style=\"text-align: right;\">          12.0183 </td><td style=\"text-align: right;\">      12.0183 </td><td style=\"text-align: right;\"> 1683751820</td><td style=\"text-align: right;\">                   1</td><td>ef910_00070</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00071</td><td>2023-05-10_16-50-15</td><td>True  </td><td>71_batch_size=32,lr=0.0159,n_hidden_dim=2,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11646e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             6.31419</td><td style=\"text-align: right;\">           6.31419</td><td style=\"text-align: right;\">       6.31419</td><td style=\"text-align: right;\"> 1683751815</td><td style=\"text-align: right;\">                   1</td><td>ef910_00071</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00072</td><td>2023-05-10_16-50-17</td><td>True  </td><td>72_batch_size=32,lr=0.0625,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             8.32276</td><td style=\"text-align: right;\">           8.32276</td><td style=\"text-align: right;\">       8.32276</td><td style=\"text-align: right;\"> 1683751817</td><td style=\"text-align: right;\">                   1</td><td>ef910_00072</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00073</td><td>2023-05-10_16-50-15</td><td>True  </td><td>73_batch_size=32,lr=0.0198,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             4.26152</td><td style=\"text-align: right;\">           4.26152</td><td style=\"text-align: right;\">       4.26152</td><td style=\"text-align: right;\"> 1683751815</td><td style=\"text-align: right;\">                   1</td><td>ef910_00073</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00074</td><td>2023-05-10_16-50-20</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.18591e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.20117</td><td style=\"text-align: right;\">           5.20117</td><td style=\"text-align: right;\">       5.20117</td><td style=\"text-align: right;\"> 1683751820</td><td style=\"text-align: right;\">                   1</td><td>ef910_00074</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00075</td><td>2023-05-10_16-50-25</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11662e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            10.4404 </td><td style=\"text-align: right;\">          10.4404 </td><td style=\"text-align: right;\">      10.4404 </td><td style=\"text-align: right;\"> 1683751825</td><td style=\"text-align: right;\">                   1</td><td>ef910_00075</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00076</td><td>2023-05-10_16-50-29</td><td>True  </td><td>76_batch_size=32,lr=0.0159,n_hidden_dim=1,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11646e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            11.5227 </td><td style=\"text-align: right;\">          11.5227 </td><td style=\"text-align: right;\">      11.5227 </td><td style=\"text-align: right;\"> 1683751829</td><td style=\"text-align: right;\">                   1</td><td>ef910_00076</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00077</td><td>2023-05-10_16-50-26</td><td>True  </td><td>77_batch_size=32,lr=0.0005,n_hidden_dim=2,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11605e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.91602</td><td style=\"text-align: right;\">           5.91602</td><td style=\"text-align: right;\">       5.91602</td><td style=\"text-align: right;\"> 1683751826</td><td style=\"text-align: right;\">                   1</td><td>ef910_00077</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00078</td><td>2023-05-10_16-50-28</td><td>True  </td><td>78_batch_size=32,lr=0.0098,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             8.37391</td><td style=\"text-align: right;\">           8.37391</td><td style=\"text-align: right;\">       8.37391</td><td style=\"text-align: right;\"> 1683751828</td><td style=\"text-align: right;\">                   1</td><td>ef910_00078</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00079</td><td>2023-05-10_16-50-34</td><td>True  </td><td>79_batch_size=32,lr=0.0192,n_hidden_dim=2,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             8.70208</td><td style=\"text-align: right;\">           8.70208</td><td style=\"text-align: right;\">       8.70208</td><td style=\"text-align: right;\"> 1683751834</td><td style=\"text-align: right;\">                   1</td><td>ef910_00079</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00080</td><td>2023-05-10_16-50-36</td><td>True  </td><td>80_batch_size=32,lr=0.0009,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11588e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">            10.3242 </td><td style=\"text-align: right;\">          10.3242 </td><td style=\"text-align: right;\">      10.3242 </td><td style=\"text-align: right;\"> 1683751836</td><td style=\"text-align: right;\">                   1</td><td>ef910_00080</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00081</td><td>2023-05-10_16-50-34</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11732e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.3405 </td><td style=\"text-align: right;\">           5.3405 </td><td style=\"text-align: right;\">       5.3405 </td><td style=\"text-align: right;\"> 1683751834</td><td style=\"text-align: right;\">                   1</td><td>ef910_00081</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00082</td><td>2023-05-10_16-50-41</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11659e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            12.1948 </td><td style=\"text-align: right;\">          12.1948 </td><td style=\"text-align: right;\">      12.1948 </td><td style=\"text-align: right;\"> 1683751841</td><td style=\"text-align: right;\">                   1</td><td>ef910_00082</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00083</td><td>2023-05-10_16-50-46</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.16694e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            12.5857 </td><td style=\"text-align: right;\">          12.5857 </td><td style=\"text-align: right;\">      12.5857 </td><td style=\"text-align: right;\"> 1683751846</td><td style=\"text-align: right;\">                   1</td><td>ef910_00083</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00084</td><td>2023-05-10_16-50-39</td><td>True  </td><td>84_batch_size=32,lr=0.0001,n_hidden_dim=1,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             4.74998</td><td style=\"text-align: right;\">           4.74998</td><td style=\"text-align: right;\">       4.74998</td><td style=\"text-align: right;\"> 1683751839</td><td style=\"text-align: right;\">                   1</td><td>ef910_00084</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00085</td><td>2023-05-10_16-50-45</td><td>True  </td><td>85_batch_size=32,lr=0.0053,n_hidden_dim=2,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             8.66632</td><td style=\"text-align: right;\">           8.66632</td><td style=\"text-align: right;\">       8.66632</td><td style=\"text-align: right;\"> 1683751845</td><td style=\"text-align: right;\">                   1</td><td>ef910_00085</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00086</td><td>2023-05-10_16-50-44</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11853e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.02876</td><td style=\"text-align: right;\">           5.02876</td><td style=\"text-align: right;\">       5.02876</td><td style=\"text-align: right;\"> 1683751844</td><td style=\"text-align: right;\">                   1</td><td>ef910_00086</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00087</td><td>2023-05-10_16-50-46</td><td>True  </td><td>87_batch_size=32,lr=0.0149,n_hidden_dim=2,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11638e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             4.95288</td><td style=\"text-align: right;\">           4.95288</td><td style=\"text-align: right;\">       4.95288</td><td style=\"text-align: right;\"> 1683751846</td><td style=\"text-align: right;\">                   1</td><td>ef910_00087</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00088</td><td>2023-05-10_16-50-56</td><td>True  </td><td>88_batch_size=32,lr=0.0005,n_hidden_dim=1,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11603e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            11.7032 </td><td style=\"text-align: right;\">          11.7032 </td><td style=\"text-align: right;\">      11.7032 </td><td style=\"text-align: right;\"> 1683751856</td><td style=\"text-align: right;\">                   1</td><td>ef910_00088</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00089</td><td>2023-05-10_16-50-51</td><td>True  </td><td>89_batch_size=32,lr=0.0139,n_hidden_dim=2,n_layers=3,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.1163e+06 </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.86461</td><td style=\"text-align: right;\">           5.86461</td><td style=\"text-align: right;\">       5.86461</td><td style=\"text-align: right;\"> 1683751851</td><td style=\"text-align: right;\">                   1</td><td>ef910_00089</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00090</td><td>2023-05-10_16-50-55</td><td>True  </td><td>90_batch_size=32,lr=0.0009,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             8.2973 </td><td style=\"text-align: right;\">           8.2973 </td><td style=\"text-align: right;\">       8.2973 </td><td style=\"text-align: right;\"> 1683751855</td><td style=\"text-align: right;\">                   1</td><td>ef910_00090</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00091</td><td>2023-05-10_16-50-51</td><td>True  </td><td>91_batch_size=32,lr=0.0003,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11611e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             4.10959</td><td style=\"text-align: right;\">           4.10959</td><td style=\"text-align: right;\">       4.10959</td><td style=\"text-align: right;\"> 1683751851</td><td style=\"text-align: right;\">                   1</td><td>ef910_00091</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00092</td><td>2023-05-10_16-51-00</td><td>True  </td><td>92_batch_size=32,lr=0.0014,n_hidden_dim=1,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11608e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             9.56607</td><td style=\"text-align: right;\">           9.56607</td><td style=\"text-align: right;\">       9.56607</td><td style=\"text-align: right;\"> 1683751860</td><td style=\"text-align: right;\">                   1</td><td>ef910_00092</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00093</td><td>2023-05-10_16-51-01</td><td>True  </td><td>93_batch_size=32,lr=0.0005,n_hidden_dim=2,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11605e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             9.85283</td><td style=\"text-align: right;\">           9.85283</td><td style=\"text-align: right;\">       9.85283</td><td style=\"text-align: right;\"> 1683751861</td><td style=\"text-align: right;\">                   1</td><td>ef910_00093</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00094</td><td>2023-05-10_16-51-08</td><td>True  </td><td>94_batch_size=32,lr=0.0004,n_hidden_dim=1,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.1161e+06 </td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            12.7964 </td><td style=\"text-align: right;\">          12.7964 </td><td style=\"text-align: right;\">      12.7964 </td><td style=\"text-align: right;\"> 1683751868</td><td style=\"text-align: right;\">                   1</td><td>ef910_00094</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00095</td><td>2023-05-10_16-51-09</td><td>True  </td><td>95_batch_size=32,lr=0.0001,n_hidden_dim=2,n_layers=3,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            12.9566 </td><td style=\"text-align: right;\">          12.9566 </td><td style=\"text-align: right;\">      12.9566 </td><td style=\"text-align: right;\"> 1683751869</td><td style=\"text-align: right;\">                   1</td><td>ef910_00095</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00096</td><td>2023-05-10_16-51-10</td><td>True  </td><td>96_batch_size=32,lr=0.0017,n_hidden_dim=1,n_layers=1,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             9.18885</td><td style=\"text-align: right;\">           9.18885</td><td style=\"text-align: right;\">       9.18885</td><td style=\"text-align: right;\"> 1683751870</td><td style=\"text-align: right;\">                   1</td><td>ef910_00096</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00097</td><td>2023-05-10_16-51-06</td><td>True  </td><td>97_batch_size=32,lr=0.0007,n_hidden_dim=2,n_layers=1,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.02243</td><td style=\"text-align: right;\">           5.02243</td><td style=\"text-align: right;\">       5.02243</td><td style=\"text-align: right;\"> 1683751866</td><td style=\"text-align: right;\">                   1</td><td>ef910_00097</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00098</td><td>2023-05-10_16-51-11</td><td>True  </td><td>98_batch_size=32,lr=0.0005,n_hidden_dim=1,n_layers=2,train_iterations=50  </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11606e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.03564</td><td style=\"text-align: right;\">           5.03564</td><td style=\"text-align: right;\">       5.03564</td><td style=\"text-align: right;\"> 1683751871</td><td style=\"text-align: right;\">                   1</td><td>ef910_00098</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00099</td><td>2023-05-10_16-51-19</td><td>True  </td><td>99_batch_size=32,lr=0.0005,n_hidden_dim=2,n_layers=2,train_iterations=100 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11603e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            11.0827 </td><td style=\"text-align: right;\">          11.0827 </td><td style=\"text-align: right;\">      11.0827 </td><td style=\"text-align: right;\"> 1683751879</td><td style=\"text-align: right;\">                   1</td><td>ef910_00099</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00100</td><td>2023-05-10_16-51-22</td><td>True  </td><td>100_batch_size=32,lr=0.0011,n_hidden_dim=1,n_layers=3,train_iterations=100</td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11589e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">            12.6181 </td><td style=\"text-align: right;\">          12.6181 </td><td style=\"text-align: right;\">      12.6181 </td><td style=\"text-align: right;\"> 1683751882</td><td style=\"text-align: right;\">                   1</td><td>ef910_00100</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00101</td><td>2023-05-10_16-51-16</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11662e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             6.18105</td><td style=\"text-align: right;\">           6.18105</td><td style=\"text-align: right;\">       6.18105</td><td style=\"text-align: right;\"> 1683751876</td><td style=\"text-align: right;\">                   1</td><td>ef910_00101</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00102</td><td>2023-05-10_16-51-16</td><td>True  </td><td>102_batch_size=32,lr=0.0110,n_hidden_dim=1,n_layers=1,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.40489</td><td style=\"text-align: right;\">           4.40489</td><td style=\"text-align: right;\">       4.40489</td><td style=\"text-align: right;\"> 1683751876</td><td style=\"text-align: right;\">                   1</td><td>ef910_00102</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00103</td><td>2023-05-10_16-51-20</td><td>True  </td><td>103_batch_size=32,lr=0.0109,n_hidden_dim=2,n_layers=1,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.58896</td><td style=\"text-align: right;\">           4.58896</td><td style=\"text-align: right;\">       4.58896</td><td style=\"text-align: right;\"> 1683751880</td><td style=\"text-align: right;\">                   1</td><td>ef910_00103</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00104</td><td>2023-05-10_16-51-21</td><td>True  </td><td>104_batch_size=32,lr=0.0009,n_hidden_dim=1,n_layers=2,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11588e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.23074</td><td style=\"text-align: right;\">           5.23074</td><td style=\"text-align: right;\">       5.23074</td><td style=\"text-align: right;\"> 1683751881</td><td style=\"text-align: right;\">                   1</td><td>ef910_00104</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00105</td><td>2023-05-10_16-51-30</td><td>True  </td><td>105_batch_size=32,lr=0.0005,n_hidden_dim=2,n_layers=2,train_iterations=100</td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11603e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            11.5026 </td><td style=\"text-align: right;\">          11.5026 </td><td style=\"text-align: right;\">      11.5026 </td><td style=\"text-align: right;\"> 1683751890</td><td style=\"text-align: right;\">                   1</td><td>ef910_00105</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00106</td><td>2023-05-10_16-51-33</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.12205e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">            12.7639 </td><td style=\"text-align: right;\">          12.7639 </td><td style=\"text-align: right;\">      12.7639 </td><td style=\"text-align: right;\"> 1683751893</td><td style=\"text-align: right;\">                   1</td><td>ef910_00106</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00107</td><td>2023-05-10_16-51-28</td><td>True  </td><td>107_batch_size=32,lr=0.0007,n_hidden_dim=2,n_layers=3,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11595e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             6.70737</td><td style=\"text-align: right;\">           6.70737</td><td style=\"text-align: right;\">       6.70737</td><td style=\"text-align: right;\"> 1683751888</td><td style=\"text-align: right;\">                   1</td><td>ef910_00107</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00108</td><td>2023-05-10_16-51-31</td><td>True  </td><td>108_batch_size=32,lr=0.0364,n_hidden_dim=1,n_layers=1,train_iterations=100</td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             9.55016</td><td style=\"text-align: right;\">           9.55016</td><td style=\"text-align: right;\">       9.55016</td><td style=\"text-align: right;\"> 1683751891</td><td style=\"text-align: right;\">                   1</td><td>ef910_00108</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00109</td><td>2023-05-10_16-51-32</td><td>True  </td><td>109_batch_size=32,lr=0.0033,n_hidden_dim=2,n_layers=1,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             4.27909</td><td style=\"text-align: right;\">           4.27909</td><td style=\"text-align: right;\">       4.27909</td><td style=\"text-align: right;\"> 1683751892</td><td style=\"text-align: right;\">                   1</td><td>ef910_00109</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00110</td><td>2023-05-10_16-51-41</td><td>True  </td><td>110_batch_size=32,lr=0.0009,n_hidden_dim=1,n_layers=2,train_iterations=100</td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11588e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">            10.4937 </td><td style=\"text-align: right;\">          10.4937 </td><td style=\"text-align: right;\">      10.4937 </td><td style=\"text-align: right;\"> 1683751901</td><td style=\"text-align: right;\">                   1</td><td>ef910_00110</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00111</td><td>2023-05-10_16-51-37</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11664e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.37501</td><td style=\"text-align: right;\">           5.37501</td><td style=\"text-align: right;\">       5.37501</td><td style=\"text-align: right;\"> 1683751897</td><td style=\"text-align: right;\">                   1</td><td>ef910_00111</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00112</td><td>2023-05-10_16-51-44</td><td>True  </td><td>112_batch_size=32,lr=0.0002,n_hidden_dim=1,n_layers=3,train_iterations=100</td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">            11.5991 </td><td style=\"text-align: right;\">          11.5991 </td><td style=\"text-align: right;\">      11.5991 </td><td style=\"text-align: right;\"> 1683751904</td><td style=\"text-align: right;\">                   1</td><td>ef910_00112</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00113</td><td>2023-05-10_16-51-39</td><td>True  </td><td>113_batch_size=32,lr=0.0003,n_hidden_dim=2,n_layers=3,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11611e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             5.98759</td><td style=\"text-align: right;\">           5.98759</td><td style=\"text-align: right;\">       5.98759</td><td style=\"text-align: right;\"> 1683751899</td><td style=\"text-align: right;\">                   1</td><td>ef910_00113</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00114</td><td>2023-05-10_16-51-45</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.20437e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             8.4362 </td><td style=\"text-align: right;\">           8.4362 </td><td style=\"text-align: right;\">       8.4362 </td><td style=\"text-align: right;\"> 1683751905</td><td style=\"text-align: right;\">                   1</td><td>ef910_00114</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00115</td><td>2023-05-10_16-51-44</td><td>True  </td><td>115_batch_size=32,lr=0.0002,n_hidden_dim=2,n_layers=1,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">nan          </td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.1344 </td><td style=\"text-align: right;\">           4.1344 </td><td style=\"text-align: right;\">       4.1344 </td><td style=\"text-align: right;\"> 1683751904</td><td style=\"text-align: right;\">                   1</td><td>ef910_00115</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00116</td><td>2023-05-10_16-51-46</td><td>True  </td><td>116_batch_size=32,lr=0.0002,n_hidden_dim=1,n_layers=2,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76485</td><td>True               </td><td style=\"text-align: right;\">             5.00403</td><td style=\"text-align: right;\">           5.00403</td><td style=\"text-align: right;\">       5.00403</td><td style=\"text-align: right;\"> 1683751906</td><td style=\"text-align: right;\">                   1</td><td>ef910_00116</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00117</td><td>2023-05-10_16-51-48</td><td>True  </td><td>                                                                          </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.18414e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76484</td><td>True               </td><td style=\"text-align: right;\">             4.73235</td><td style=\"text-align: right;\">           4.73235</td><td style=\"text-align: right;\">       4.73235</td><td style=\"text-align: right;\"> 1683751908</td><td style=\"text-align: right;\">                   1</td><td>ef910_00117</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00118</td><td>2023-05-10_16-51-49</td><td>True  </td><td>118_batch_size=32,lr=0.0001,n_hidden_dim=1,n_layers=3,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11612e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76483</td><td>True               </td><td style=\"text-align: right;\">             5.27436</td><td style=\"text-align: right;\">           5.27436</td><td style=\"text-align: right;\">       5.27436</td><td style=\"text-align: right;\"> 1683751909</td><td style=\"text-align: right;\">                   1</td><td>ef910_00118</td></tr>\n",
       "<tr><td>train_and_validate_ef910_00119</td><td>2023-05-10_16-51-51</td><td>True  </td><td>119_batch_size=32,lr=0.0015,n_hidden_dim=2,n_layers=3,train_iterations=50 </td><td>dhcp-10-29-108-17.dyn.MIT.EDU</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">  1.11619e+06</td><td>127.0.0.1</td><td style=\"text-align: right;\">76488</td><td>True               </td><td style=\"text-align: right;\">             5.36512</td><td style=\"text-align: right;\">           5.36512</td><td style=\"text-align: right;\">       5.36512</td><td style=\"text-align: right;\"> 1683751911</td><td style=\"text-align: right;\">                   1</td><td>ef910_00119</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:47:59,750\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:47:59 (running for 00:00:05.95)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116098.125\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 20/120 (16 PENDING, 4 RUNNING)\n",
      "+--------------------------------+----------+-----------------+--------------+-------------+----------------+------------+--------------------+------------+----------------------+\n",
      "| Trial name                     | status   | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |       loss |   training_iteration |\n",
      "|--------------------------------+----------+-----------------+--------------+-------------+----------------+------------+--------------------+------------+----------------------|\n",
      "| train_and_validate_ef910_00000 | RUNNING  | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 | 1.1161e+06 |                    1 |\n",
      "| train_and_validate_ef910_00001 | RUNNING  | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00002 | RUNNING  | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00003 | RUNNING  | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00004 | PENDING  |                 |           32 | 0.000388301 |              1 |          3 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00005 | PENDING  |                 |           32 | 0.00265981  |              2 |          3 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00006 | PENDING  |                 |           32 | 0.0160185   |              1 |          1 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00007 | PENDING  |                 |           32 | 0.000957223 |              2 |          1 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00008 | PENDING  |                 |           32 | 0.00710632  |              1 |          2 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00009 | PENDING  |                 |           32 | 0.000175338 |              2 |          2 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00010 | PENDING  |                 |           32 | 0.000121385 |              1 |          3 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00011 | PENDING  |                 |           32 | 0.0396404   |              2 |          3 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00012 | PENDING  |                 |           32 | 0.00416303  |              1 |          1 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00013 | PENDING  |                 |           32 | 0.000609101 |              2 |          1 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00014 | PENDING  |                 |           32 | 0.000508702 |              1 |          2 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00015 | PENDING  |                 |           32 | 0.0146762   |              2 |          2 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00016 | PENDING  |                 |           32 | 0.00243986  |              1 |          3 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00017 | PENDING  |                 |           32 | 0.00402871  |              2 |          3 |                 50 |            |                      |\n",
      "| train_and_validate_ef910_00018 | PENDING  |                 |           32 | 0.00150779  |              1 |          1 |                100 |            |                      |\n",
      "| train_and_validate_ef910_00019 | PENDING  |                 |           32 | 0.000282671 |              2 |          1 |                100 |            |                      |\n",
      "+--------------------------------+----------+-----------------+--------------+-------------+----------------+------------+--------------------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 17940x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 4600628.5\u001b[32m [repeated 53380x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:01,372\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:02,300\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:02,411\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:05,579\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:05 (running for 00:00:11.78)\n",
      "Using AsyncHyperBand: num_stopped=1\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116096.0\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 24/120 (16 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00004 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00006 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00007 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00008 | PENDING    |                 |           32 | 0.00710632  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00009 | PENDING    |                 |           32 | 0.000175338 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00010 | PENDING    |                 |           32 | 0.000121385 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00011 | PENDING    |                 |           32 | 0.0396404   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00012 | PENDING    |                 |           32 | 0.00416303  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00013 | PENDING    |                 |           32 | 0.000609101 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00014 | PENDING    |                 |           32 | 0.000508702 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00015 | PENDING    |                 |           32 | 0.0146762   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00016 | PENDING    |                 |           32 | 0.00243986  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00017 | PENDING    |                 |           32 | 0.00402871  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00018 | PENDING    |                 |           32 | 0.00150779  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00019 | PENDING    |                 |           32 | 0.000282671 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 4 more trials not shown (4 PENDING)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 36286x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m 13\u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 198071.203125\u001b[32m [repeated 47041x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:06,560\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:10,452\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 30061x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m 13\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 1248835.125\u001b[32m [repeated 57178x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:10,854\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:10 (running for 00:00:17.06)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116098.125\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 27/120 (16 PENDING, 4 RUNNING, 7 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00005 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00007 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00009 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000175338 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00010 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000121385 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00011 | PENDING    |                 |           32 | 0.0396404   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00012 | PENDING    |                 |           32 | 0.00416303  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00013 | PENDING    |                 |           32 | 0.000609101 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00014 | PENDING    |                 |           32 | 0.000508702 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00015 | PENDING    |                 |           32 | 0.0146762   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00016 | PENDING    |                 |           32 | 0.00243986  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00017 | PENDING    |                 |           32 | 0.00402871  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00018 | PENDING    |                 |           32 | 0.00150779  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00019 | PENDING    |                 |           32 | 0.000282671 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00008 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00710632  |              1 |          2 |                 50 |   1.11713e+06 |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 7 more trials not shown (7 PENDING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:13,027\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 894x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 321807.46875\u001b[32m [repeated 78912x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:16,148\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:16 (running for 00:00:22.35)\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116117.0\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 29/120 (16 PENDING, 4 RUNNING, 9 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00009 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000175338 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00010 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000121385 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00011 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0396404   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00012 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00416303  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00013 | PENDING    |                 |           32 | 0.000609101 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00014 | PENDING    |                 |           32 | 0.000508702 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00015 | PENDING    |                 |           32 | 0.0146762   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00016 | PENDING    |                 |           32 | 0.00243986  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00017 | PENDING    |                 |           32 | 0.00402871  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00018 | PENDING    |                 |           32 | 0.00150779  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00019 | PENDING    |                 |           32 | 0.000282671 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00020 | PENDING    |                 |           32 | 0.00212832  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 9 more trials not shown (8 PENDING, 1 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:16,852\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:16,914\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:20,344\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 36568x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 153183.21875\u001b[32m [repeated 53545x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 1449913.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:21,332\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:21 (running for 00:00:27.54)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116628.1875\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 33/120 (16 PENDING, 4 RUNNING, 13 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00012 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00416303  |              1 |          1 |                100 |   1.11859e+06 |                    1 |\n",
      "| train_and_validate_ef910_00014 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000508702 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00015 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0146762   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00016 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00243986  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00017 | PENDING    |                 |           32 | 0.00402871  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00018 | PENDING    |                 |           32 | 0.00150779  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00019 | PENDING    |                 |           32 | 0.000282671 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00020 | PENDING    |                 |           32 | 0.00212832  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00021 | PENDING    |                 |           32 | 0.00166033  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00022 | PENDING    |                 |           32 | 0.0441236   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00023 | PENDING    |                 |           32 | 0.0238317   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00024 | PENDING    |                 |           32 | 0.000125847 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 13 more trials not shown (8 PENDING, 5 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:22,120\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 23676x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 275199.5\u001b[32m [repeated 59836x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:26,959\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:26 (running for 00:00:33.16)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116125.375\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 35/120 (16 PENDING, 4 RUNNING, 15 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00014 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000508702 |              1 |          2 |                100 |   1.11604e+06 |                    1 |\n",
      "| train_and_validate_ef910_00016 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00243986  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00017 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00402871  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00018 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00150779  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00019 | PENDING    |                 |           32 | 0.000282671 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00020 | PENDING    |                 |           32 | 0.00212832  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00021 | PENDING    |                 |           32 | 0.00166033  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00022 | PENDING    |                 |           32 | 0.0441236   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00023 | PENDING    |                 |           32 | 0.0238317   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00024 | PENDING    |                 |           32 | 0.000125847 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00025 | PENDING    |                 |           32 | 0.0491878   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00026 | PENDING    |                 |           32 | 0.00013516  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 15 more trials not shown (8 PENDING, 7 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 641137.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:27,289\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 43337x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 1027862.375\u001b[32m [repeated 43979x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:30,697\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:31,759\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:32,229\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:32 (running for 00:00:38.43)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1117112.9375\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 39/120 (16 PENDING, 4 RUNNING, 19 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00019 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000282671 |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00020 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00212832  |              1 |          2 |                 50 |   1.11709e+06 |                    1 |\n",
      "| train_and_validate_ef910_00021 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00166033  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00022 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0441236   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00023 | PENDING    |                 |           32 | 0.0238317   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00024 | PENDING    |                 |           32 | 0.000125847 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00025 | PENDING    |                 |           32 | 0.0491878   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00026 | PENDING    |                 |           32 | 0.00013516  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00027 | PENDING    |                 |           32 | 0.000431184 |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00028 | PENDING    |                 |           32 | 0.000589298 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00029 | PENDING    |                 |           32 | 0.00140026  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00030 | PENDING    |                 |           32 | 0.00153028  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 19 more trials not shown (8 PENDING, 11 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:35,473\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 24535x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m 13\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 351553.09375\u001b[32m [repeated 57372x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:36,007\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:38,197\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:38 (running for 00:00:44.40)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116837.6875\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 42/120 (16 PENDING, 4 RUNNING, 22 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00022 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0441236   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00023 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0238317   |              2 |          3 |                 50 |   1.11658e+06 |                    1 |\n",
      "| train_and_validate_ef910_00024 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000125847 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00025 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0491878   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00026 | PENDING    |                 |           32 | 0.00013516  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00027 | PENDING    |                 |           32 | 0.000431184 |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00028 | PENDING    |                 |           32 | 0.000589298 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00029 | PENDING    |                 |           32 | 0.00140026  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00030 | PENDING    |                 |           32 | 0.00153028  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00031 | PENDING    |                 |           32 | 0.0820627   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00032 | PENDING    |                 |           32 | 0.0972039   |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00033 | PENDING    |                 |           32 | 0.0705531   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 22 more trials not shown (8 PENDING, 14 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:40,374\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 551026.5625\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 46892x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m 13\u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 195121.875\u001b[32m [repeated 40675x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:43,125\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:43,849\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:43 (running for 00:00:50.05)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1117094.875\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 45/120 (16 PENDING, 4 RUNNING, 25 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00024 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000125847 |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00026 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00013516  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00027 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000431184 |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00028 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000589298 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00029 | PENDING    |                 |           32 | 0.00140026  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00030 | PENDING    |                 |           32 | 0.00153028  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00031 | PENDING    |                 |           32 | 0.0820627   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00032 | PENDING    |                 |           32 | 0.0972039   |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00033 | PENDING    |                 |           32 | 0.0705531   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00034 | PENDING    |                 |           32 | 0.000253638 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00035 | PENDING    |                 |           32 | 0.00390418  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00036 | PENDING    |                 |           32 | 0.00065269  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 25 more trials not shown (8 PENDING, 17 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 16435x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 190252.3125\u001b[32m [repeated 66455x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:45,705\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:48,141\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 37543x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 281469.90625\u001b[32m [repeated 47578x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:52,353\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:52 (running for 00:00:58.56)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116580.5\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 48/120 (16 PENDING, 4 RUNNING, 28 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00028 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000589298 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00029 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00140026  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00030 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00153028  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00031 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0820627   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00032 | PENDING    |                 |           32 | 0.0972039   |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00033 | PENDING    |                 |           32 | 0.0705531   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00034 | PENDING    |                 |           32 | 0.000253638 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00035 | PENDING    |                 |           32 | 0.00390418  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00036 | PENDING    |                 |           32 | 0.00065269  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00037 | PENDING    |                 |           32 | 0.00245812  |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00038 | PENDING    |                 |           32 | 0.0169376   |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00039 | PENDING    |                 |           32 | 0.00401917  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 28 more trials not shown (8 PENDING, 20 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:54,208\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:54,626\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 26347x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 119191.984375\u001b[32m [repeated 55946x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:55,846\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:48:57,444\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:48:57 (running for 00:01:03.65)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116489.0625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 52/120 (16 PENDING, 4 RUNNING, 32 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00032 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0972039   |              1 |          2 |                 50 |   1.19694e+06 |                    1 |\n",
      "| train_and_validate_ef910_00033 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0705531   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00034 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000253638 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00035 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00390418  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00036 | PENDING    |                 |           32 | 0.00065269  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00037 | PENDING    |                 |           32 | 0.00245812  |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00038 | PENDING    |                 |           32 | 0.0169376   |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00039 | PENDING    |                 |           32 | 0.00401917  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00040 | PENDING    |                 |           32 | 0.061034    |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00041 | PENDING    |                 |           32 | 0.0264708   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00042 | PENDING    |                 |           32 | 0.000108861 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00043 | PENDING    |                 |           32 | 0.000257974 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 32 more trials not shown (8 PENDING, 24 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:48:59,599\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:49:00,477\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 21336x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m 13\u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 81265.125\u001b[32m [repeated 58389x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 362960.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:04,045\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:04 (running for 00:01:10.25)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116489.0625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 55/120 (16 PENDING, 4 RUNNING, 35 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00035 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00390418  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00036 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00065269  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00037 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00245812  |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00038 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0169376   |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00039 | PENDING    |                 |           32 | 0.00401917  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00040 | PENDING    |                 |           32 | 0.061034    |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00041 | PENDING    |                 |           32 | 0.0264708   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00042 | PENDING    |                 |           32 | 0.000108861 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00043 | PENDING    |                 |           32 | 0.000257974 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00044 | PENDING    |                 |           32 | 0.012881    |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00045 | PENDING    |                 |           32 | 0.00238832  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00046 | PENDING    |                 |           32 | 0.000276552 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 35 more trials not shown (8 PENDING, 27 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 4528233.5\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 41690x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 4528233.5\u001b[32m [repeated 45347x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:05,842\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:08,038\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:49:10,377\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:10 (running for 00:01:16.58)\n",
      "Using AsyncHyperBand: num_stopped=11\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116566.5625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 58/120 (16 PENDING, 4 RUNNING, 38 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00038 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0169376   |              1 |          2 |                100 |   1.11655e+06 |                    1 |\n",
      "| train_and_validate_ef910_00039 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00401917  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00040 | RUNNING    | 127.0.0.1:76484 |           32 | 0.061034    |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00041 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0264708   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00042 | PENDING    |                 |           32 | 0.000108861 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00043 | PENDING    |                 |           32 | 0.000257974 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00044 | PENDING    |                 |           32 | 0.012881    |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00045 | PENDING    |                 |           32 | 0.00238832  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00046 | PENDING    |                 |           32 | 0.000276552 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00047 | PENDING    |                 |           32 | 0.00208475  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00048 | PENDING    |                 |           32 | 0.0300878   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00049 | PENDING    |                 |           32 | 0.0161793   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 38 more trials not shown (8 PENDING, 30 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 1910x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m \u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 870761.8125\u001b[32m [repeated 76013x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:11,671\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:49:14,021\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:49:14,542\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 46700x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 1375475.125\u001b[32m [repeated 43032x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:15,875\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:15 (running for 00:01:22.08)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116876.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 62/120 (16 PENDING, 4 RUNNING, 42 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00042 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000108861 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00043 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000257974 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00044 | RUNNING    | 127.0.0.1:76488 |           32 | 0.012881    |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00045 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00238832  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00046 | PENDING    |                 |           32 | 0.000276552 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00047 | PENDING    |                 |           32 | 0.00208475  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00048 | PENDING    |                 |           32 | 0.0300878   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00049 | PENDING    |                 |           32 | 0.0161793   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00050 | PENDING    |                 |           32 | 0.000605384 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00051 | PENDING    |                 |           32 | 0.0334432   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00052 | PENDING    |                 |           32 | 0.000430932 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00053 | PENDING    |                 |           32 | 0.000641643 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 42 more trials not shown (8 PENDING, 34 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:18,594\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 16115x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 236616.703125\u001b[32m [repeated 66291x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:21,724\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:21 (running for 00:01:27.93)\n",
      "Using AsyncHyperBand: num_stopped=14\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116728.5625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 64/120 (16 PENDING, 4 RUNNING, 44 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00044 | RUNNING    | 127.0.0.1:76488 |           32 | 0.012881    |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00045 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00238832  |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00046 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000276552 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00047 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00208475  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00048 | PENDING    |                 |           32 | 0.0300878   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00049 | PENDING    |                 |           32 | 0.0161793   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00050 | PENDING    |                 |           32 | 0.000605384 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00051 | PENDING    |                 |           32 | 0.0334432   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00052 | PENDING    |                 |           32 | 0.000430932 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00053 | PENDING    |                 |           32 | 0.000641643 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00054 | PENDING    |                 |           32 | 0.0018819   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00055 | PENDING    |                 |           32 | 0.00153437  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 44 more trials not shown (8 PENDING, 36 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:24,040\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:24,481\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:49:25,086\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 7747x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 58x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 149387.015625\u001b[32m [repeated 77902x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:25,882\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:28,379\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:28 (running for 00:01:34.58)\n",
      "Using AsyncHyperBand: num_stopped=17\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116952.1875\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 69/120 (16 PENDING, 4 RUNNING, 49 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00049 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0161793   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00050 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000605384 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00051 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0334432   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00052 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000430932 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00053 | PENDING    |                 |           32 | 0.000641643 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00054 | PENDING    |                 |           32 | 0.0018819   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00055 | PENDING    |                 |           32 | 0.00153437  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00056 | PENDING    |                 |           32 | 0.00204792  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00057 | PENDING    |                 |           32 | 0.000237709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00058 | PENDING    |                 |           32 | 0.0152697   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00059 | PENDING    |                 |           32 | 0.000419395 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00060 | PENDING    |                 |           32 | 0.0679632   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 49 more trials not shown (8 PENDING, 41 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:30,311\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 15105x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m \u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 166348.9375\u001b[32m [repeated 67556x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:34,262\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:34 (running for 00:01:40.46)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116952.1875\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 71/120 (16 PENDING, 4 RUNNING, 51 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00050 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000605384 |              1 |          2 |                100 |   1.11599e+06 |                    1 |\n",
      "| train_and_validate_ef910_00052 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000430932 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00053 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000641643 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00054 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0018819   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00055 | PENDING    |                 |           32 | 0.00153437  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00056 | PENDING    |                 |           32 | 0.00204792  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00057 | PENDING    |                 |           32 | 0.000237709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00058 | PENDING    |                 |           32 | 0.0152697   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00059 | PENDING    |                 |           32 | 0.000419395 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00060 | PENDING    |                 |           32 | 0.0679632   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00061 | PENDING    |                 |           32 | 0.00151059  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00062 | PENDING    |                 |           32 | 0.00110602  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 51 more trials not shown (8 PENDING, 43 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 31427x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 140124.890625\u001b[32m [repeated 50849x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:37,629\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:39,034\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:49:40,563\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:40 (running for 00:01:46.76)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116728.5625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 74/120 (16 PENDING, 4 RUNNING, 54 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00053 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000641643 |              2 |          3 |                100 |   1.11597e+06 |                    1 |\n",
      "| train_and_validate_ef910_00055 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00153437  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00056 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00204792  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00057 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000237709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00058 | PENDING    |                 |           32 | 0.0152697   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00059 | PENDING    |                 |           32 | 0.000419395 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00060 | PENDING    |                 |           32 | 0.0679632   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00061 | PENDING    |                 |           32 | 0.00151059  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00062 | PENDING    |                 |           32 | 0.00110602  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00063 | PENDING    |                 |           32 | 0.0272142   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00064 | PENDING    |                 |           32 | 0.0576627   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00065 | PENDING    |                 |           32 | 0.00126962  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 54 more trials not shown (8 PENDING, 46 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 42764x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 436449.5625\u001b[32m [repeated 43411x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:42,486\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 9441x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m \u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 1269580.5\u001b[32m [repeated 71704x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:46,495\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:46 (running for 00:01:52.70)\n",
      "Using AsyncHyperBand: num_stopped=18\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116580.5\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 76/120 (16 PENDING, 4 RUNNING, 56 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00056 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00204792  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00057 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000237709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00058 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0152697   |              1 |          3 |                 50 |   1.11641e+06 |                    1 |\n",
      "| train_and_validate_ef910_00059 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000419395 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00060 | PENDING    |                 |           32 | 0.0679632   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00061 | PENDING    |                 |           32 | 0.00151059  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00062 | PENDING    |                 |           32 | 0.00110602  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00063 | PENDING    |                 |           32 | 0.0272142   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00064 | PENDING    |                 |           32 | 0.0576627   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00065 | PENDING    |                 |           32 | 0.00126962  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00066 | PENDING    |                 |           32 | 0.000787586 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00067 | PENDING    |                 |           32 | 0.0625528   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 56 more trials not shown (8 PENDING, 48 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:47,656\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:49,504\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 36033x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m \u001b[32m [repeated 49x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 2374913.0\u001b[32m [repeated 49950x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 292025.4375\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 390716.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:54,196\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:54 (running for 00:02:00.40)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116566.5625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 79/120 (16 PENDING, 4 RUNNING, 59 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00059 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000419395 |              2 |          3 |                100 |   1.11608e+06 |                    1 |\n",
      "| train_and_validate_ef910_00060 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0679632   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00061 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00151059  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00062 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00110602  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00063 | PENDING    |                 |           32 | 0.0272142   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00064 | PENDING    |                 |           32 | 0.0576627   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00065 | PENDING    |                 |           32 | 0.00126962  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00066 | PENDING    |                 |           32 | 0.000787586 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00067 | PENDING    |                 |           32 | 0.0625528   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00068 | PENDING    |                 |           32 | 0.000383087 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00069 | PENDING    |                 |           32 | 0.00577435  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00070 | PENDING    |                 |           32 | 0.0125169   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 59 more trials not shown (8 PENDING, 51 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:54,996\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 47102x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 33x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 928848.0\u001b[32m [repeated 42402x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:56,084\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:49:59,958\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:49:59 (running for 00:02:06.16)\n",
      "Using AsyncHyperBand: num_stopped=19\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116552.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 82/120 (16 PENDING, 4 RUNNING, 62 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00062 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00110602  |              1 |          2 |                100 |   1.1159e+06  |                    1 |\n",
      "| train_and_validate_ef910_00063 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0272142   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00064 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0576627   |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00065 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00126962  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00066 | PENDING    |                 |           32 | 0.000787586 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00067 | PENDING    |                 |           32 | 0.0625528   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00068 | PENDING    |                 |           32 | 0.000383087 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00069 | PENDING    |                 |           32 | 0.00577435  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00070 | PENDING    |                 |           32 | 0.0125169   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00071 | PENDING    |                 |           32 | 0.0158531   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00072 | PENDING    |                 |           32 | 0.0625235   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00073 | PENDING    |                 |           32 | 0.0197933   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 62 more trials not shown (8 PENDING, 54 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 5158x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m \u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 558603.4375\u001b[32m [repeated 69984x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:01,238\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:04,451\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:05,564\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:05 (running for 00:02:11.77)\n",
      "Using AsyncHyperBand: num_stopped=21\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116580.5\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 85/120 (16 PENDING, 4 RUNNING, 65 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00065 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00126962  |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00066 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000787586 |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00067 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0625528   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00068 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000383087 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00069 | PENDING    |                 |           32 | 0.00577435  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00070 | PENDING    |                 |           32 | 0.0125169   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00071 | PENDING    |                 |           32 | 0.0158531   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00072 | PENDING    |                 |           32 | 0.0625235   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00073 | PENDING    |                 |           32 | 0.0197933   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00074 | PENDING    |                 |           32 | 0.0493645   |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00075 | PENDING    |                 |           32 | 0.0180566   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00076 | PENDING    |                 |           32 | 0.0158627   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 65 more trials not shown (8 PENDING, 57 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 46282x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m 13\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 2756290.5\u001b[32m [repeated 41202x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:08,186\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:50:08,640\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:09,605\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: inf\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 19188x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m \u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 79236.890625\u001b[32m [repeated 59217x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:11,146\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:11 (running for 00:02:17.34)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116566.5625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 89/120 (16 PENDING, 4 RUNNING, 69 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00069 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00577435  |              2 |          2 |                 50 |   1.11785e+06 |                    1 |\n",
      "| train_and_validate_ef910_00070 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0125169   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00071 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0158531   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00072 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0625235   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00073 | PENDING    |                 |           32 | 0.0197933   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00074 | PENDING    |                 |           32 | 0.0493645   |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00075 | PENDING    |                 |           32 | 0.0180566   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00076 | PENDING    |                 |           32 | 0.0158627   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00077 | PENDING    |                 |           32 | 0.000478582 |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00078 | PENDING    |                 |           32 | 0.00980606  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00079 | PENDING    |                 |           32 | 0.0191971   |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00080 | PENDING    |                 |           32 | 0.000933464 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 69 more trials not shown (8 PENDING, 61 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:15,032\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 541917.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:15,459\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 47275x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m 13\u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 448216.375\u001b[32m [repeated 37788x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:18,028\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:18 (running for 00:02:24.23)\n",
      "Using AsyncHyperBand: num_stopped=22\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116552.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 92/120 (16 PENDING, 4 RUNNING, 72 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00070 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0125169   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00072 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0625235   |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00074 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0493645   |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00075 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0180566   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00076 | PENDING    |                 |           32 | 0.0158627   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00077 | PENDING    |                 |           32 | 0.000478582 |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00078 | PENDING    |                 |           32 | 0.00980606  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00079 | PENDING    |                 |           32 | 0.0191971   |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00080 | PENDING    |                 |           32 | 0.000933464 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00081 | PENDING    |                 |           32 | 0.00671294  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00082 | PENDING    |                 |           32 | 0.01745     |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00083 | PENDING    |                 |           32 | 0.0456254   |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 72 more trials not shown (8 PENDING, 64 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:20,334\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:50:20,412\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 12968x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m 13\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 122837.625\u001b[32m [repeated 65405x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:25 (running for 00:02:31.72)\n",
      "Using AsyncHyperBand: num_stopped=23\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116552.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 95/120 (16 PENDING, 4 RUNNING, 75 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00075 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0180566   |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00076 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0158627   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00077 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000478582 |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00078 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00980606  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00079 | PENDING    |                 |           32 | 0.0191971   |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00080 | PENDING    |                 |           32 | 0.000933464 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00081 | PENDING    |                 |           32 | 0.00671294  |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00082 | PENDING    |                 |           32 | 0.01745     |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00083 | PENDING    |                 |           32 | 0.0456254   |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00084 | PENDING    |                 |           32 | 0.000131246 |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00085 | PENDING    |                 |           32 | 0.00531503  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00086 | PENDING    |                 |           32 | 0.00444892  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 75 more trials not shown (8 PENDING, 67 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 25590x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 162010.21875\u001b[32m [repeated 57938x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:25,979\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [  1]\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:26,333\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:50:28,845\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:29,646\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 39033x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 55x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 469555.03125\u001b[32m [repeated 46664x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:34,268\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:34 (running for 00:02:40.47)\n",
      "Using AsyncHyperBand: num_stopped=25\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116552.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 99/120 (16 PENDING, 4 RUNNING, 79 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00079 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0191971   |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00080 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000933464 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00081 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00671294  |              2 |          2 |                 50 |   1.11732e+06 |                    1 |\n",
      "| train_and_validate_ef910_00082 | RUNNING    | 127.0.0.1:76483 |           32 | 0.01745     |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00083 | PENDING    |                 |           32 | 0.0456254   |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00084 | PENDING    |                 |           32 | 0.000131246 |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00085 | PENDING    |                 |           32 | 0.00531503  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00086 | PENDING    |                 |           32 | 0.00444892  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00087 | PENDING    |                 |           32 | 0.0148895   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00088 | PENDING    |                 |           32 | 0.000530529 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00089 | PENDING    |                 |           32 | 0.0138528   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00090 | PENDING    |                 |           32 | 0.00089829  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 79 more trials not shown (8 PENDING, 71 TERMINATED)\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 93093.8046875\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:34,742\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 23889x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m \u001b[32m [repeated 36x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 122176.3359375\u001b[32m [repeated 57602x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:36,764\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:39,587\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:39 (running for 00:02:45.79)\n",
      "Using AsyncHyperBand: num_stopped=25\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116508.0625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 102/120 (16 PENDING, 4 RUNNING, 82 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00082 | RUNNING    | 127.0.0.1:76483 |           32 | 0.01745     |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00083 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0456254   |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00084 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000131246 |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00085 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00531503  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00086 | PENDING    |                 |           32 | 0.00444892  |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00087 | PENDING    |                 |           32 | 0.0148895   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00088 | PENDING    |                 |           32 | 0.000530529 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00089 | PENDING    |                 |           32 | 0.0138528   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00090 | PENDING    |                 |           32 | 0.00089829  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00091 | PENDING    |                 |           32 | 0.0003309   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00092 | PENDING    |                 |           32 | 0.00139025  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00093 | PENDING    |                 |           32 | 0.000481026 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 82 more trials not shown (8 PENDING, 74 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 961456.75\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 34884x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 46x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 275279.65625\u001b[32m [repeated 40119x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:41,932\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:44,743\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:44 (running for 00:02:50.94)\n",
      "Using AsyncHyperBand: num_stopped=27\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116566.5625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 104/120 (16 PENDING, 4 RUNNING, 84 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00083 | RUNNING    | 127.0.0.1:76485 |           32 | 0.0456254   |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00085 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00531503  |              2 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00086 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00444892  |              1 |          2 |                 50 |   1.11853e+06 |                    1 |\n",
      "| train_and_validate_ef910_00087 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0148895   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00088 | PENDING    |                 |           32 | 0.000530529 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00089 | PENDING    |                 |           32 | 0.0138528   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00090 | PENDING    |                 |           32 | 0.00089829  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00091 | PENDING    |                 |           32 | 0.0003309   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00092 | PENDING    |                 |           32 | 0.00139025  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00093 | PENDING    |                 |           32 | 0.000481026 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00094 | PENDING    |                 |           32 | 0.000381813 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00095 | PENDING    |                 |           32 | 0.000117946 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 84 more trials not shown (8 PENDING, 76 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:45,510\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 24646x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m \u001b[32m [repeated 51x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 615694.125\u001b[32m [repeated 59149x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:46,914\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:46,991\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 19131x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 178977.046875\u001b[32m [repeated 64990x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:51,199\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:51 (running for 00:02:57.40)\n",
      "Using AsyncHyperBand: num_stopped=28\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116552.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 108/120 (16 PENDING, 4 RUNNING, 88 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00088 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000530529 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00089 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0138528   |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00090 | RUNNING    | 127.0.0.1:76485 |           32 | 0.00089829  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00091 | RUNNING    | 127.0.0.1:76483 |           32 | 0.0003309   |              2 |          1 |                 50 |   1.11611e+06 |                    1 |\n",
      "| train_and_validate_ef910_00092 | PENDING    |                 |           32 | 0.00139025  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00093 | PENDING    |                 |           32 | 0.000481026 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00094 | PENDING    |                 |           32 | 0.000381813 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00095 | PENDING    |                 |           32 | 0.000117946 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00096 | PENDING    |                 |           32 | 0.00166173  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00097 | PENDING    |                 |           32 | 0.000656997 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00098 | PENDING    |                 |           32 | 0.000471117 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00099 | PENDING    |                 |           32 | 0.000518932 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 88 more trials not shown (8 PENDING, 80 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:51,467\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:55,265\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 23459x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 804528.5625\u001b[32m [repeated 61835x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:50:56,518\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:50:56 (running for 00:03:02.72)\n",
      "Using AsyncHyperBand: num_stopped=28\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116463.5\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 111/120 (16 PENDING, 4 RUNNING, 91 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00088 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000530529 |              1 |          3 |                100 |   1.11603e+06 |                    1 |\n",
      "| train_and_validate_ef910_00092 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00139025  |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00093 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000481026 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00094 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000381813 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00095 | PENDING    |                 |           32 | 0.000117946 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00096 | PENDING    |                 |           32 | 0.00166173  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00097 | PENDING    |                 |           32 | 0.000656997 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00098 | PENDING    |                 |           32 | 0.000471117 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00099 | PENDING    |                 |           32 | 0.000518932 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00100 | PENDING    |                 |           32 | 0.00106557  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00101 | PENDING    |                 |           32 | 0.00855238  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00102 | PENDING    |                 |           32 | 0.0110457   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 91 more trials not shown (8 PENDING, 83 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 109068.15625\u001b[32m [repeated 80374x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:00,887\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:01,418\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 74x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 188107.734375\u001b[32m [repeated 35027x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 37945x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:06,551\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:06 (running for 00:03:12.75)\n",
      "Using AsyncHyperBand: num_stopped=28\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116462.625\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 114/120 (16 PENDING, 4 RUNNING, 94 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00094 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000381813 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00095 | RUNNING    | 127.0.0.1:76488 |           32 | 0.000117946 |              2 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00096 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00166173  |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00097 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000656997 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00098 | PENDING    |                 |           32 | 0.000471117 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00099 | PENDING    |                 |           32 | 0.000518932 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00100 | PENDING    |                 |           32 | 0.00106557  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00101 | PENDING    |                 |           32 | 0.00855238  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00102 | PENDING    |                 |           32 | 0.0110457   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00103 | PENDING    |                 |           32 | 0.0108868   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00104 | PENDING    |                 |           32 | 0.000888672 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00105 | PENDING    |                 |           32 | 0.000533709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 94 more trials not shown (8 PENDING, 86 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:08,149\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:09,576\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:10,171\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 61x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 2832912.5\u001b[32m [repeated 51762x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 22984x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:11,692\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:11 (running for 00:03:17.89)\n",
      "Using AsyncHyperBand: num_stopped=28\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116403.75\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 118/120 (16 PENDING, 4 RUNNING, 98 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00098 | RUNNING    | 127.0.0.1:76484 |           32 | 0.000471117 |              1 |          2 |                 50 |   1.11606e+06 |                    1 |\n",
      "| train_and_validate_ef910_00099 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000518932 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00100 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00106557  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00101 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00855238  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00102 | PENDING    |                 |           32 | 0.0110457   |              1 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00103 | PENDING    |                 |           32 | 0.0108868   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00104 | PENDING    |                 |           32 | 0.000888672 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00105 | PENDING    |                 |           32 | 0.000533709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00106 | PENDING    |                 |           32 | 0.0325705   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00107 | PENDING    |                 |           32 | 0.000684942 |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00108 | PENDING    |                 |           32 | 0.0364093   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00109 | PENDING    |                 |           32 | 0.00331138  |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 98 more trials not shown (8 PENDING, 90 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m \u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 119650.5546875\u001b[32m [repeated 58075x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 20381x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:16,206\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:16,455\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:19,344\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:19 (running for 00:03:25.55)\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116403.75\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (15 PENDING, 4 RUNNING, 101 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00099 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000518932 |              2 |          2 |                100 |   1.11603e+06 |                    1 |\n",
      "| train_and_validate_ef910_00100 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00106557  |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00103 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0108868   |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00104 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000888672 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00105 | PENDING    |                 |           32 | 0.000533709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00106 | PENDING    |                 |           32 | 0.0325705   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00107 | PENDING    |                 |           32 | 0.000684942 |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00108 | PENDING    |                 |           32 | 0.0364093   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00109 | PENDING    |                 |           32 | 0.00331138  |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00110 | PENDING    |                 |           32 | 0.000878275 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00111 | PENDING    |                 |           32 | 0.0248652   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00112 | PENDING    |                 |           32 | 0.000167005 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 100 more trials not shown (7 PENDING, 93 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 47x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 136883.5\u001b[32m [repeated 53905x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:20,895\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 22210x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:21,764\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:22,292\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 35x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 494793.09375\u001b[32m [repeated 59755x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 17609x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:27 (running for 00:03:33.61)\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116386.875\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (11 PENDING, 4 RUNNING, 105 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00105 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000533709 |              2 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00106 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0325705   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00107 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000684942 |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00108 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0364093   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00109 | PENDING    |                 |           32 | 0.00331138  |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00110 | PENDING    |                 |           32 | 0.000878275 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00111 | PENDING    |                 |           32 | 0.0248652   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00112 | PENDING    |                 |           32 | 0.000167005 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00113 | PENDING    |                 |           32 | 0.00033663  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00114 | PENDING    |                 |           32 | 0.0569069   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00115 | PENDING    |                 |           32 | 0.000154433 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00116 | PENDING    |                 |           32 | 0.000165027 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 100 more trials not shown (3 PENDING, 97 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:28,569\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 251705.03125\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m \u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: 709206.5\u001b[32m [repeated 40177x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:30,940\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 32321x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  ...\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:31,939\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:32,953\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:32 (running for 00:03:39.16)\n",
      "Using AsyncHyperBand: num_stopped=29\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116335.75\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (8 PENDING, 4 RUNNING, 108 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00106 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0325705   |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00109 | RUNNING    | 127.0.0.1:76483 |           32 | 0.00331138  |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00110 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000878275 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00111 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0248652   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00112 | PENDING    |                 |           32 | 0.000167005 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00113 | PENDING    |                 |           32 | 0.00033663  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00114 | PENDING    |                 |           32 | 0.0569069   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00115 | PENDING    |                 |           32 | 0.000154433 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00116 | PENDING    |                 |           32 | 0.000165027 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00117 | PENDING    |                 |           32 | 0.0490005   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00118 | PENDING    |                 |           32 | 0.000131072 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00119 | PENDING    |                 |           32 | 0.00149661  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 100 more trials not shown (100 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:33,763\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 45x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m Mean Train MSE: 544224.125\u001b[32m [repeated 62092x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 13957x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:37,407\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:39,822\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:39 (running for 00:03:46.02)\n",
      "Using AsyncHyperBand: num_stopped=31\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116376.125\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (5 PENDING, 4 RUNNING, 111 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00110 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000878275 |              1 |          2 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00112 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000167005 |              1 |          3 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00113 | RUNNING    | 127.0.0.1:76484 |           32 | 0.00033663  |              2 |          3 |                 50 |   1.11611e+06 |                    1 |\n",
      "| train_and_validate_ef910_00114 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0569069   |              1 |          1 |                100 |               |                      |\n",
      "| train_and_validate_ef910_00115 | PENDING    |                 |           32 | 0.000154433 |              2 |          1 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00116 | PENDING    |                 |           32 | 0.000165027 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00117 | PENDING    |                 |           32 | 0.0490005   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00118 | PENDING    |                 |           32 | 0.000131072 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00119 | PENDING    |                 |           32 | 0.00149661  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00008 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00710632  |              1 |          2 |                 50 |   1.11713e+06 |                    1 |\n",
      "| train_and_validate_ef910_00009 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000175338 |              2 |          2 |                100 |   1.11613e+06 |                    1 |\n",
      "| train_and_validate_ef910_00010 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000121385 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 100 more trials not shown (100 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: inf\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76485)\u001b[0m \u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 1171121.75\u001b[32m [repeated 75070x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 5527x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  ...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m  [ 23]\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:41,524\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:44,067\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:44,656\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m \u001b[32m [repeated 43x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76483)\u001b[0m Mean Train MSE: 905191.25\u001b[32m [repeated 71753x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:45,919\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:45 (running for 00:03:52.12)\n",
      "Using AsyncHyperBand: num_stopped=32\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116335.75\n",
      "Logical resource usage: 8.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (1 PENDING, 4 RUNNING, 115 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00114 | RUNNING    | 127.0.0.1:76488 |           32 | 0.0569069   |              1 |          1 |                100 |   1.20437e+06 |                    1 |\n",
      "| train_and_validate_ef910_00116 | RUNNING    | 127.0.0.1:76485 |           32 | 0.000165027 |              1 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00117 | RUNNING    | 127.0.0.1:76484 |           32 | 0.0490005   |              2 |          2 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00118 | RUNNING    | 127.0.0.1:76483 |           32 | 0.000131072 |              1 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00119 | PENDING    |                 |           32 | 0.00149661  |              2 |          3 |                 50 |               |                      |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00008 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00710632  |              1 |          2 |                 50 |   1.11713e+06 |                    1 |\n",
      "| train_and_validate_ef910_00009 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000175338 |              2 |          2 |                100 |   1.11613e+06 |                    1 |\n",
      "| train_and_validate_ef910_00010 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000121385 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00011 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0396404   |              2 |          3 |                 50 |   1.14115e+06 |                    1 |\n",
      "| train_and_validate_ef910_00012 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00416303  |              1 |          1 |                100 |   1.11859e+06 |                    1 |\n",
      "| train_and_validate_ef910_00013 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000609101 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00014 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000508702 |              1 |          2 |                100 |   1.11604e+06 |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 100 more trials not shown (100 TERMINATED)\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76484)\u001b[0m Mean Train MSE: nan\u001b[32m [repeated 15762x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  ...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m  [ 23]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:46,630\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:48,915\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n",
      "2023-05-10 16:51:50,015\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m \u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_and_validate pid=76488)\u001b[0m Mean Train MSE: 74457.53125\u001b[32m [repeated 55459x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:51,337\tERROR checkpoint_manager.py:361 -- Result dict has no key: validation_loss. checkpoint_score_attr must be set to a key in the result dict. Valid keys are: ['loss', 'time_this_iter_s', 'should_checkpoint', 'done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'experiment_tag', 'config/n_layers', 'config/n_hidden_dim', 'config/lr', 'config/batch_size', 'config/train_iterations']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:51 (running for 00:03:57.54)\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116271.125\n",
      "Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (1 RUNNING, 119 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00119 | RUNNING    | 127.0.0.1:76488 |           32 | 0.00149661  |              2 |          3 |                 50 |   1.11619e+06 |                    1 |\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00008 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00710632  |              1 |          2 |                 50 |   1.11713e+06 |                    1 |\n",
      "| train_and_validate_ef910_00009 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000175338 |              2 |          2 |                100 |   1.11613e+06 |                    1 |\n",
      "| train_and_validate_ef910_00010 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000121385 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00011 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0396404   |              2 |          3 |                 50 |   1.14115e+06 |                    1 |\n",
      "| train_and_validate_ef910_00012 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00416303  |              1 |          1 |                100 |   1.11859e+06 |                    1 |\n",
      "| train_and_validate_ef910_00013 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000609101 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00014 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000508702 |              1 |          2 |                100 |   1.11604e+06 |                    1 |\n",
      "| train_and_validate_ef910_00015 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0146762   |              2 |          2 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00016 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00243986  |              1 |          3 |                100 |   1.11756e+06 |                    1 |\n",
      "| train_and_validate_ef910_00017 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00402871  |              2 |          3 |                 50 |   1.11861e+06 |                    1 |\n",
      "| train_and_validate_ef910_00018 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00150779  |              1 |          1 |                100 | nan           |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "... 100 more trials not shown (100 TERMINATED)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 16:51:51,378\tINFO tune.py:945 -- Total run time: 237.60 seconds (237.57 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-10 16:51:51 (running for 00:03:57.58)\n",
      "Using AsyncHyperBand: num_stopped=33\n",
      "Bracket: Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1116271.125\n",
      "Logical resource usage: 0/8 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/outputs/raytune_result/train_and_validate_2023-05-10_16-47-53\n",
      "Number of trials: 120/120 (120 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "| Trial name                     | status     | loc             |   batch_size |          lr |   n_hidden_dim |   n_layers |   train_iterations |          loss |   training_iteration |\n",
      "|--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------|\n",
      "| train_and_validate_ef910_00000 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000376769 |              1 |          1 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00001 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000646454 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00002 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00232123  |              1 |          2 |                 50 |   1.11739e+06 |                    1 |\n",
      "| train_and_validate_ef910_00003 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000441908 |              2 |          2 |                 50 |   1.11607e+06 |                    1 |\n",
      "| train_and_validate_ef910_00004 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000388301 |              1 |          3 |                 50 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00005 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00265981  |              2 |          3 |                100 |   1.11784e+06 |                    1 |\n",
      "| train_and_validate_ef910_00006 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0160185   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00007 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000957223 |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00008 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00710632  |              1 |          2 |                 50 |   1.11713e+06 |                    1 |\n",
      "| train_and_validate_ef910_00009 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000175338 |              2 |          2 |                100 |   1.11613e+06 |                    1 |\n",
      "| train_and_validate_ef910_00010 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000121385 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00011 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0396404   |              2 |          3 |                 50 |   1.14115e+06 |                    1 |\n",
      "| train_and_validate_ef910_00012 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00416303  |              1 |          1 |                100 |   1.11859e+06 |                    1 |\n",
      "| train_and_validate_ef910_00013 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000609101 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00014 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000508702 |              1 |          2 |                100 |   1.11604e+06 |                    1 |\n",
      "| train_and_validate_ef910_00015 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0146762   |              2 |          2 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00016 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00243986  |              1 |          3 |                100 |   1.11756e+06 |                    1 |\n",
      "| train_and_validate_ef910_00017 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00402871  |              2 |          3 |                 50 |   1.11861e+06 |                    1 |\n",
      "| train_and_validate_ef910_00018 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00150779  |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00019 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000282671 |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00020 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00212832  |              1 |          2 |                 50 |   1.11709e+06 |                    1 |\n",
      "| train_and_validate_ef910_00021 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00166033  |              2 |          2 |                 50 |   1.1164e+06  |                    1 |\n",
      "| train_and_validate_ef910_00022 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0441236   |              1 |          3 |                100 |   1.15961e+06 |                    1 |\n",
      "| train_and_validate_ef910_00023 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0238317   |              2 |          3 |                 50 |   1.11658e+06 |                    1 |\n",
      "| train_and_validate_ef910_00024 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000125847 |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00025 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0491878   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00026 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00013516  |              1 |          2 |                100 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00027 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000431184 |              2 |          2 |                 50 |   1.11608e+06 |                    1 |\n",
      "| train_and_validate_ef910_00028 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000589298 |              1 |          3 |                100 |   1.116e+06   |                    1 |\n",
      "| train_and_validate_ef910_00029 | TERMINATED | 127.0.0.1:76488 |           32 | 0.00140026  |              2 |          3 |                100 |   1.11609e+06 |                    1 |\n",
      "| train_and_validate_ef910_00030 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00153028  |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00031 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0820627   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00032 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0972039   |              1 |          2 |                 50 |   1.19694e+06 |                    1 |\n",
      "| train_and_validate_ef910_00033 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0705531   |              2 |          2 |                 50 |   1.17626e+06 |                    1 |\n",
      "| train_and_validate_ef910_00034 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000253638 |              1 |          3 |                 50 |   1.11613e+06 |                    1 |\n",
      "| train_and_validate_ef910_00035 | TERMINATED | 127.0.0.1:76488 |           32 | 0.00390418  |              2 |          3 |                100 |   1.11861e+06 |                    1 |\n",
      "| train_and_validate_ef910_00036 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00065269  |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00037 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00245812  |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00038 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0169376   |              1 |          2 |                100 |   1.11655e+06 |                    1 |\n",
      "| train_and_validate_ef910_00039 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00401917  |              2 |          2 |                100 |   1.11861e+06 |                    1 |\n",
      "| train_and_validate_ef910_00040 | TERMINATED | 127.0.0.1:76484 |           32 | 0.061034    |              1 |          3 |                 50 |   1.19759e+06 |                    1 |\n",
      "| train_and_validate_ef910_00041 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0264708   |              2 |          3 |                 50 |   1.11688e+06 |                    1 |\n",
      "| train_and_validate_ef910_00042 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000108861 |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00043 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000257974 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00044 | TERMINATED | 127.0.0.1:76488 |           32 | 0.012881    |              1 |          2 |                100 |   1.11625e+06 |                    1 |\n",
      "| train_and_validate_ef910_00045 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00238832  |              2 |          2 |                100 |   1.11748e+06 |                    1 |\n",
      "| train_and_validate_ef910_00046 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000276552 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00047 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00208475  |              2 |          3 |                 50 |   1.11703e+06 |                    1 |\n",
      "| train_and_validate_ef910_00048 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0300878   |              1 |          1 |                 50 |   1.11881e+06 |                    1 |\n",
      "| train_and_validate_ef910_00049 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0161793   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00050 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000605384 |              1 |          2 |                100 |   1.11599e+06 |                    1 |\n",
      "| train_and_validate_ef910_00051 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0334432   |              2 |          2 |                 50 |   1.12365e+06 |                    1 |\n",
      "| train_and_validate_ef910_00052 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000430932 |              1 |          3 |                100 |   1.11608e+06 |                    1 |\n",
      "| train_and_validate_ef910_00053 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000641643 |              2 |          3 |                100 |   1.11597e+06 |                    1 |\n",
      "| train_and_validate_ef910_00054 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0018819   |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00055 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00153437  |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00056 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00204792  |              1 |          2 |                100 |   1.11697e+06 |                    1 |\n",
      "| train_and_validate_ef910_00057 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000237709 |              2 |          2 |                100 |   1.11613e+06 |                    1 |\n",
      "| train_and_validate_ef910_00058 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0152697   |              1 |          3 |                 50 |   1.11641e+06 |                    1 |\n",
      "| train_and_validate_ef910_00059 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000419395 |              2 |          3 |                100 |   1.11608e+06 |                    1 |\n",
      "| train_and_validate_ef910_00060 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0679632   |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00061 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00151059  |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00062 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00110602  |              1 |          2 |                100 |   1.1159e+06  |                    1 |\n",
      "| train_and_validate_ef910_00063 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0272142   |              2 |          2 |                100 |   1.11708e+06 |                    1 |\n",
      "| train_and_validate_ef910_00064 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0576627   |              1 |          3 |                 50 |   1.20382e+06 |                    1 |\n",
      "| train_and_validate_ef910_00065 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00126962  |              2 |          3 |                100 |   1.11599e+06 |                    1 |\n",
      "| train_and_validate_ef910_00066 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000787586 |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00067 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0625528   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00068 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000383087 |              1 |          2 |                 50 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00069 | TERMINATED | 127.0.0.1:76488 |           32 | 0.00577435  |              2 |          2 |                 50 |   1.11785e+06 |                    1 |\n",
      "| train_and_validate_ef910_00070 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0125169   |              1 |          3 |                100 |   1.11624e+06 |                    1 |\n",
      "| train_and_validate_ef910_00071 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0158531   |              2 |          3 |                 50 |   1.11646e+06 |                    1 |\n",
      "| train_and_validate_ef910_00072 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0625235   |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00073 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0197933   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00074 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0493645   |              1 |          2 |                 50 |   1.18591e+06 |                    1 |\n",
      "| train_and_validate_ef910_00075 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0180566   |              2 |          2 |                100 |   1.11662e+06 |                    1 |\n",
      "| train_and_validate_ef910_00076 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0158627   |              1 |          3 |                100 |   1.11646e+06 |                    1 |\n",
      "| train_and_validate_ef910_00077 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000478582 |              2 |          3 |                 50 |   1.11605e+06 |                    1 |\n",
      "| train_and_validate_ef910_00078 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00980606  |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00079 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0191971   |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00080 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000933464 |              1 |          2 |                100 |   1.11588e+06 |                    1 |\n",
      "| train_and_validate_ef910_00081 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00671294  |              2 |          2 |                 50 |   1.11732e+06 |                    1 |\n",
      "| train_and_validate_ef910_00082 | TERMINATED | 127.0.0.1:76483 |           32 | 0.01745     |              1 |          3 |                100 |   1.11659e+06 |                    1 |\n",
      "| train_and_validate_ef910_00083 | TERMINATED | 127.0.0.1:76485 |           32 | 0.0456254   |              2 |          3 |                100 |   1.16694e+06 |                    1 |\n",
      "| train_and_validate_ef910_00084 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000131246 |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00085 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00531503  |              2 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00086 | TERMINATED | 127.0.0.1:76488 |           32 | 0.00444892  |              1 |          2 |                 50 |   1.11853e+06 |                    1 |\n",
      "| train_and_validate_ef910_00087 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0148895   |              2 |          2 |                 50 |   1.11638e+06 |                    1 |\n",
      "| train_and_validate_ef910_00088 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000530529 |              1 |          3 |                100 |   1.11603e+06 |                    1 |\n",
      "| train_and_validate_ef910_00089 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0138528   |              2 |          3 |                 50 |   1.1163e+06  |                    1 |\n",
      "| train_and_validate_ef910_00090 | TERMINATED | 127.0.0.1:76485 |           32 | 0.00089829  |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00091 | TERMINATED | 127.0.0.1:76483 |           32 | 0.0003309   |              2 |          1 |                 50 |   1.11611e+06 |                    1 |\n",
      "| train_and_validate_ef910_00092 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00139025  |              1 |          2 |                100 |   1.11608e+06 |                    1 |\n",
      "| train_and_validate_ef910_00093 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000481026 |              2 |          2 |                100 |   1.11605e+06 |                    1 |\n",
      "| train_and_validate_ef910_00094 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000381813 |              1 |          3 |                100 |   1.1161e+06  |                    1 |\n",
      "| train_and_validate_ef910_00095 | TERMINATED | 127.0.0.1:76488 |           32 | 0.000117946 |              2 |          3 |                100 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00096 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00166173  |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00097 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000656997 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00098 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000471117 |              1 |          2 |                 50 |   1.11606e+06 |                    1 |\n",
      "| train_and_validate_ef910_00099 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000518932 |              2 |          2 |                100 |   1.11603e+06 |                    1 |\n",
      "| train_and_validate_ef910_00100 | TERMINATED | 127.0.0.1:76488 |           32 | 0.00106557  |              1 |          3 |                100 |   1.11589e+06 |                    1 |\n",
      "| train_and_validate_ef910_00101 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00855238  |              2 |          3 |                 50 |   1.11662e+06 |                    1 |\n",
      "| train_and_validate_ef910_00102 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0110457   |              1 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00103 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0108868   |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00104 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000888672 |              1 |          2 |                 50 |   1.11588e+06 |                    1 |\n",
      "| train_and_validate_ef910_00105 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000533709 |              2 |          2 |                100 |   1.11603e+06 |                    1 |\n",
      "| train_and_validate_ef910_00106 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0325705   |              1 |          3 |                100 |   1.12205e+06 |                    1 |\n",
      "| train_and_validate_ef910_00107 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000684942 |              2 |          3 |                 50 |   1.11595e+06 |                    1 |\n",
      "| train_and_validate_ef910_00108 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0364093   |              1 |          1 |                100 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00109 | TERMINATED | 127.0.0.1:76483 |           32 | 0.00331138  |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00110 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000878275 |              1 |          2 |                100 |   1.11588e+06 |                    1 |\n",
      "| train_and_validate_ef910_00111 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0248652   |              2 |          2 |                 50 |   1.11664e+06 |                    1 |\n",
      "| train_and_validate_ef910_00112 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000167005 |              1 |          3 |                100 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00113 | TERMINATED | 127.0.0.1:76484 |           32 | 0.00033663  |              2 |          3 |                 50 |   1.11611e+06 |                    1 |\n",
      "| train_and_validate_ef910_00114 | TERMINATED | 127.0.0.1:76488 |           32 | 0.0569069   |              1 |          1 |                100 |   1.20437e+06 |                    1 |\n",
      "| train_and_validate_ef910_00115 | TERMINATED | 127.0.0.1:76484 |           32 | 0.000154433 |              2 |          1 |                 50 | nan           |                    1 |\n",
      "| train_and_validate_ef910_00116 | TERMINATED | 127.0.0.1:76485 |           32 | 0.000165027 |              1 |          2 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00117 | TERMINATED | 127.0.0.1:76484 |           32 | 0.0490005   |              2 |          2 |                 50 |   1.18414e+06 |                    1 |\n",
      "| train_and_validate_ef910_00118 | TERMINATED | 127.0.0.1:76483 |           32 | 0.000131072 |              1 |          3 |                 50 |   1.11612e+06 |                    1 |\n",
      "| train_and_validate_ef910_00119 | TERMINATED | 127.0.0.1:76488 |           32 | 0.00149661  |              2 |          3 |                 50 |   1.11619e+06 |                    1 |\n",
      "+--------------------------------+------------+-----------------+--------------+-------------+----------------+------------+--------------------+---------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'n_layers': 2, 'n_hidden_dim': 1, 'lr': 0.0009334638817662335, 'batch_size': 32, 'train_iterations': 100}\n",
      "Best trial final validation loss: 1115877.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000006?line=1'>2</a>\u001b[0m     main()\n",
      "\u001b[1;32m/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb Cell 6'\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=57'>58</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest trial config: \u001b[39m\u001b[39m{\u001b[39;00mbest_trial\u001b[39m.\u001b[39mconfig\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=58'>59</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest trial final validation loss: \u001b[39m\u001b[39m{\u001b[39;00mbest_trial\u001b[39m.\u001b[39mlast_result[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=59'>60</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest trial final validation acc: \u001b[39m\u001b[39m{\u001b[39;00mbest_trial\u001b[39m.\u001b[39mlast_result[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=62'>63</a>\u001b[0m     \u001b[39m#n_layers = np.arange(1, 5) # iterate through hidden layer count\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=63'>64</a>\u001b[0m     \u001b[39m#n_hidden_dim = np.arange(8, 65, 8)  # iterate through hidden layer node count\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=64'>65</a>\u001b[0m     \u001b[39m#mse_dict = {}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=90'>91</a>\u001b[0m     \u001b[39m#plt.plot(range(len(nn_model_result[1])), nn_model_result[1])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=91'>92</a>\u001b[0m     \u001b[39m# axis labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=93'>94</a>\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=94'>95</a>\u001b[0m \u001b[39m    plt.xlabel('Iteration Step')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=95'>96</a>\u001b[0m \u001b[39m    plt.ylabel('Test Error')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=99'>100</a>\u001b[0m \u001b[39m    plt.show()\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/donokoye/Documents/Spring_23/ML_1.C51/Final_Project/ev_adoption_ml/neural_net.ipynb#ch0000005?line=100'>101</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
