{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import torch  \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Class and Training Functions\n",
    "Define Class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nn_model, X_train, y_train, X_eval, y_eval, lr=1e-4, max_iter=50, batch_size=32, print_n=10):\n",
    "    '''\n",
    "    Trains neural network model on X_train, y_train data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        matrix of training data features\n",
    "    y_train: np.array\n",
    "        vector of training data labels\n",
    "    lr: float\n",
    "        learning_rate for training\n",
    "    max_iter: int\n",
    "        maximum number of iterations to train for\n",
    "    batch_size: int\n",
    "        batch size to use when training w/ SGD\n",
    "    print_n: int\n",
    "        print training progress every print_n steps\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    '''\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "    X_test_tensor = torch.tensor(X_eval)\n",
    "    y_test_tensor = torch.tensor(y_eval)\n",
    "    # intialize neural network\n",
    "    n_samples, n_features = X_train_tensor.shape\n",
    "    nn_model.train()  # put model in train mode\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # train with (mini-batch) SGD; initialize optimizer\n",
    "    #opt = torch.optim.SGD(nn_model.parameters(), lr=lr)\n",
    "    opt = torch.optim.SGD(nn_model.parameters(), lr=lr,  momentum=0.9)\n",
    "    losses_test = []\n",
    "    # save losses across all iterations\n",
    "    losses = []\n",
    "    for it in range(max_iter):\n",
    "        loss_train_sum = 0\n",
    "        loss_test_sum = 0 \n",
    "        # loop through data in batches\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            # reset gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # form batch\n",
    "            X_batch = X_train_tensor[batch_start:batch_start+batch_size]\n",
    "            y_batch = y_train_tensor[batch_start:batch_start+batch_size]\n",
    "            X_batch_test = X_test_tensor[batch_start:batch_start+batch_size]\n",
    "            y_batch_test = y_test_tensor[batch_start:batch_start+batch_size]\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            y_pred_test = nn_model(X_batch_test.float())\n",
    "            y_pred_test = y_pred_test.unsqueeze(1)\n",
    "            # compute MSE loss\n",
    "            loss = mse_loss(y_pred, y_batch[:, None].float())\n",
    "            loss_train_sum += loss.detach().numpy()\n",
    "            loss_test = mse_loss(y_pred_test, y_batch_test[:, None].float())\n",
    "            loss_test_sum += loss_test.detach().numpy()\n",
    "            # back-propagate loss\n",
    "            loss.backward()\n",
    "            # update model parameters based on backpropogated gradients - clip values to avoid exploding gradients\n",
    "            torch.nn.utils.clip_grad_value_(nn_model.parameters(), clip_value=1.5)\n",
    "            opt.step()\n",
    "        losses.append(loss_train_sum)\n",
    "        losses_test.append(loss_test_sum)\n",
    "        \n",
    "        if it % print_n == 0:\n",
    "            print(f\"Mean Train MSE at step {it}: {loss_train_sum}\")\n",
    "\n",
    "        \n",
    "        \n",
    "    return nn_model, losses_test\n",
    "\n",
    "def evaluate_model(nn_model, X_eval, y_eval, batch_size=32):\n",
    "    '''\n",
    "    Evaluates trained neural network model on X_eval, y_eval data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    X_eval: np.array\n",
    "        matrix of training data features\n",
    "    y_eval: np.array\n",
    "        vector of training data labels\n",
    "    batch_size: int\n",
    "        batch size to looping over dataset to generate predictions\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse: float\n",
    "        MSE of trained model on X_eval, y_eval data\n",
    "    '''\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_eval_tensor = torch.tensor(X_eval)\n",
    "    y_eval_tensor = torch.tensor(y_eval)\n",
    "    n_samples = X_eval_tensor.shape[0]\n",
    "    nn_model.eval() # put in eval mode\n",
    "    # loop over data and generate predictions\n",
    "    preds = []\n",
    "    for batch_start in range(0, n_samples, batch_size):\n",
    "        # form batch\n",
    "        X_batch = X_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        y_batch = y_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        with torch.no_grad():  # no need to compute gradients during evaluation\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            preds.append(y_pred)\n",
    "    # compute MSE across all samples\n",
    "    all_preds = torch.cat(preds)\n",
    "    loss = mse_loss(all_preds, y_eval_tensor[:, None].float()).item()\n",
    "    y_pred = torch.reshape(all_preds, (y_eval.shape[0], 1))\n",
    "\n",
    "    r_square = r2_score(y_eval, y_pred)\n",
    "    return loss, r_square\n",
    "\n",
    "class NN(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            # Network should have a single hidden layer\n",
    "            # Apply ReLU activation in between the hidden layer and output node\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NN_configureable(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        #self.input_dim = input_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.layers = nn.ModuleDict()\n",
    "\n",
    "        # Define input layer\n",
    "        self.layers[\"input\"] = nn.Linear(in_features = input_dim, out_features = hidden_dim)\n",
    "        # Define hidden layers\n",
    "        for i in range(self.hidden_layers):\n",
    "            self.layers[f\"hidden_{i}\"] = nn.Linear(in_features = hidden_dim, out_features = hidden_dim)\n",
    "        # Define output layer\n",
    "        self.layers[\"output\"] = nn.Linear(in_features = hidden_dim, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers[\"input\"](x)\n",
    "        for i in range(self.hidden_layers):\n",
    "            x = F.relu(self.layers[f\"hidden_{i}\"](x))\n",
    "\n",
    "        return self.layers[\"output\"](x)        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Get data from different sources before combining\n",
    "* Cleaned up EV data: TX_WA_CO_NY.csv\n",
    "* Average EV price and new car data over time: Avg_EV_Price.csv\n",
    "* Census data (pop, household income, zipcode): census.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():   \n",
    "    # Import data\n",
    "    X = pd.read_csv('./Data/df_X_county.csv')\n",
    "    #X['constant'] = 1\n",
    "    y = pd.read_csv('./Data/df_y_county.csv')\n",
    "\n",
    "    # check if any nan values\n",
    "    nan_row_X = X[X.isna().any(axis=1)]\n",
    "    #print(nan_row_X)\n",
    "    nan_row_y = y[y.isna().any(axis=1)]\n",
    "    #print(nan_row_y)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    # only predict PHEV\n",
    "    y = y[:,0]\n",
    "\n",
    "    # split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # standardize X\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # train NN model to predict EV registration using train data\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    n_samples, n_features = X_train_tensor.shape\n",
    "    \n",
    "    # Input (manually) optimal hyper-paramater results from RayTune grid search\n",
    "    best_hidden_dim = 8\n",
    "    best_hidden_layer = 4\n",
    "    best_batch_size = 64\n",
    "    best_lr = 0.0004697091486004313\n",
    "    best_max_iter = 50\n",
    "    nn_model = NN_configureable(input_dim=n_features, hidden_dim=best_hidden_dim, hidden_layers=best_hidden_layer)\n",
    "    nn_model_result = train_model(nn_model, X_train, y_train, X_test, y_test, lr=best_lr, max_iter=best_max_iter, batch_size=best_batch_size)\n",
    "    \n",
    "    train_mse = evaluate_model(nn_model_result[0], X_train, y_train, batch_size=best_batch_size)\n",
    "    test_mse = evaluate_model(nn_model_result[0], X_test, y_test, batch_size=best_batch_size)\n",
    "    \n",
    "    # Save the trained model to the models folder\n",
    "    joblib.dump(nn_model, 'Models/model_nn.joblib')\n",
    "    \n",
    "    print(f\"Train MSE for model, dim = {best_hidden_dim} is: {train_mse} Train R-squared is: {train_mse[1]}\")\n",
    "    print(f\"Test MSE for model, dim = {best_hidden_dim} is: {test_mse[0]} Test R-squared is: {test_mse[1]}\")\n",
    "\n",
    "    '''\n",
    "    # plot 3 models test errors\n",
    "    print(nn_model_result[1])\n",
    "    plt.plot(range(len(nn_model_result[1])), nn_model_result[1])\n",
    "    # axis labels\n",
    "    plt.xlabel('Iteration Step')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.title(\"Model 1 - Hidden Layer - ReLU\")\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([42, 1])) that is different to the input size (torch.Size([42, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([0, 1])) that is different to the input size (torch.Size([0, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([39, 1])) that is different to the input size (torch.Size([39, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train MSE at step 0: 91536529.78125\n",
      "Mean Train MSE at step 10: 84340066.9921875\n",
      "Mean Train MSE at step 20: 84356850.3203125\n",
      "Mean Train MSE at step 30: 84364758.9453125\n",
      "Mean Train MSE at step 40: 84379844.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([8871, 1])) that is different to the input size (torch.Size([8871, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2218, 1])) that is different to the input size (torch.Size([2218, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE for model, dim = 8 is: (606754.5625, -0.00424957359658773) Train R-squared is: -0.00424957359658773\n",
      "Test MSE for model, dim = 8 is: 595430.625 Test R-squared is: -0.004352720448543623\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
