{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch  \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from uszipcode import SearchEngine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Class and Training Functions\n",
    "Define Class and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(nn_model, X_train, y_train, X_eval, y_eval, k, max_iter=50, batch_size=32, print_n=10):\n",
    "    '''\n",
    "    Trains neural network model on X_train, y_train data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: np.array\n",
    "        matrix of training data features\n",
    "    y_train: np.array\n",
    "        vector of training data labels\n",
    "    k: int\n",
    "        size of hidden layer to use in neural network\n",
    "    max_iter: int\n",
    "        maximum number of iterations to train for\n",
    "    batch_size: int\n",
    "        batch size to use when training w/ SGD\n",
    "    print_n: int\n",
    "        print training progress every print_n steps\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    '''\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "    X_test_tensor = torch.tensor(X_eval)\n",
    "    y_test_tensor = torch.tensor(y_eval)\n",
    "    # intialize neural network\n",
    "    n_samples, n_features = X_train_tensor.shape\n",
    "    #nn_model = NN(n_features, k)\n",
    "    nn_model.train()  # put model in train mode\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # train with (mini-batch) SGD; initialize optimizer\n",
    "    opt = torch.optim.SGD(nn_model.parameters(), lr=1e-4)\n",
    "    losses_test = []\n",
    "    # save losses across all iterations\n",
    "    losses = []\n",
    "    for it in range(max_iter):\n",
    "        loss_train_sum = 0\n",
    "        loss_test_sum = 0 \n",
    "        # loop through data in batches\n",
    "        for batch_start in range(0, n_samples, batch_size):\n",
    "            # reset gradients to zero\n",
    "            opt.zero_grad()\n",
    "            # form batch\n",
    "            X_batch = X_train_tensor[batch_start:batch_start+batch_size]\n",
    "            y_batch = y_train_tensor[batch_start:batch_start+batch_size]\n",
    "            X_batch_test = X_test_tensor[batch_start:batch_start+batch_size]\n",
    "            y_batch_test = y_test_tensor[batch_start:batch_start+batch_size]\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            y_pred_test = nn_model(X_batch_test.float())\n",
    "            y_pred_test = y_pred_test.unsqueeze(1)\n",
    "            # compute MSE loss\n",
    "            loss = mse_loss(y_pred, y_batch[:, None].float())\n",
    "            loss_train_sum += loss.detach().numpy()\n",
    "            loss_test = mse_loss(y_pred_test, y_batch_test[:, None].float())\n",
    "            loss_test_sum += loss_test.detach().numpy()\n",
    "            # back-propagate loss\n",
    "            loss.backward()\n",
    "            # update model parameters based on backpropogated gradients\n",
    "            opt.step()\n",
    "        losses.append(loss_train_sum)\n",
    "        losses_test.append(loss_test_sum)\n",
    "        \n",
    "        print(f\"Mean Train MSE at step {it}: {loss_train_sum}\")\n",
    "        \n",
    "    return nn_model, losses_test\n",
    "\n",
    "def evaluate_model(nn_model, X_eval, y_eval, batch_size=32):\n",
    "    '''\n",
    "    Evaluates trained neural network model on X_eval, y_eval data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nn_model: torch.nn.Module\n",
    "        trained neural network model\n",
    "    X_eval: np.array\n",
    "        matrix of training data features\n",
    "    y_eval: np.array\n",
    "        vector of training data labels\n",
    "    batch_size: int\n",
    "        batch size to looping over dataset to generate predictions\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mse: float\n",
    "        MSE of trained model on X_eval, y_eval data\n",
    "    '''\n",
    "    # initialize mse loss function\n",
    "    mse_loss = torch.nn.MSELoss()\n",
    "    # convert to tensors (for Pytorch)\n",
    "    X_eval_tensor = torch.tensor(X_eval)\n",
    "    y_eval_tensor = torch.tensor(y_eval)\n",
    "    n_samples = X_eval_tensor.shape[0]\n",
    "    nn_model.eval() # put in eval mode\n",
    "    # loop over data and generate predictions\n",
    "    preds = []\n",
    "    for batch_start in range(0, n_samples, batch_size):\n",
    "        # form batch\n",
    "        X_batch = X_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        y_batch = y_eval_tensor[batch_start:batch_start+batch_size]\n",
    "        with torch.no_grad():  # no need to compute gradients during evaluation\n",
    "            # pass batch through neural net to get prediction\n",
    "            y_pred = nn_model(X_batch.float())\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            preds.append(y_pred)\n",
    "    # compute MSE across all samples\n",
    "    all_preds = torch.cat(preds)\n",
    "    loss = mse_loss(all_preds, y_eval_tensor[:, None].float()).item()\n",
    "    y_pred = torch.reshape(all_preds, (y_eval.shape[0], 1))\n",
    "\n",
    "    r_square = r2_score(y_eval, y_pred)\n",
    "    return loss, r_square\n",
    "\n",
    "class NN(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = nn.Sequential(\n",
    "            # Network should have a single hidden layer\n",
    "            # Apply ReLU activation in between the hidden layer and output node\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class NN_configureable(nn.Module):\n",
    "    '''\n",
    "    Class for fully connected neural net.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, hidden_layers):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            input dimension (i.e., # of features in each example passed to the network)\n",
    "        hidden_dim: int\n",
    "            number of nodes in hidden layer\n",
    "        '''\n",
    "        super().__init__()\n",
    "        #self.input_dim = input_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.layers = nn.ModuleDict()\n",
    "\n",
    "        # Define input layer\n",
    "        self.layers[\"input\"] = nn.Linear(in_features = input_dim, out_features = hidden_dim)\n",
    "        # Define hidden layers\n",
    "        for i in range(self.hidden_layers):\n",
    "            self.layers[f\"hidden_{i}\"] = nn.Linear(in_features = hidden_dim, out_features = hidden_dim)\n",
    "        # Define output layer\n",
    "        self.layers[\"output\"] = nn.Linear(in_features = hidden_dim, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers[\"input\"](x)\n",
    "        for i in range(self.hidden_layers):\n",
    "            x = F.relu(self.layers[f\"hidden_{i}\"](x))\n",
    "\n",
    "        return self.layers[\"output\"](x)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Get data from different sources before combining\n",
    "* Cleaned up EV data: TX_WA_CO_NY.csv\n",
    "* Average EV price and new car data over time: Avg_EV_Price.csv\n",
    "* Census data (pop, household income, zipcode): census.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():   \n",
    "    # Import data\n",
    "    X = pd.read_csv('./Data/df_X_county.csv')\n",
    "    X['constant'] = 1\n",
    "    y = pd.read_csv('./Data/df_y_county.csv')\n",
    "\n",
    "    # check if any nan values\n",
    "    nan_row_X = X[X.isna().any(axis=1)]\n",
    "    #print(nan_row_X)\n",
    "    nan_row_y = y[y.isna().any(axis=1)]\n",
    "    #print(nan_row_y)\n",
    "\n",
    "    X = X.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "\n",
    "    # split train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # standardize X\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #print(X_test.shape)\n",
    "    #print(y_test.shape)\n",
    "    \n",
    "    # train NN model to predict EV registration using train data\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    n_samples, input_dim = X_train_tensor.shape\n",
    "\n",
    "    nn_model_place = NN(input_dim, 8)\n",
    "    nn_model_result = train_model(nn_model_place, X_train, y_train, X_test, y_test, 32)\n",
    "    print(nn_model_result[1][0])\n",
    "    train_mse = evaluate_model(nn_model_result[0], X_train, y_train)\n",
    "    test_mse = evaluate_model(nn_model_result[0], X_test, y_test)\n",
    "    \n",
    "    \n",
    "    print(f\"Train MSE for model, dim = {8} is: {train_mse} Train R-squared is: {train_mse[1]}\")\n",
    "    print(f\"Test MSE for model, dim = {8} is: {test_mse[0]} Test R-squared is: {test_mse[1]}\")\n",
    "\n",
    "    '''\n",
    "    # plot 3 models test errors\n",
    "    print(nn_model_result[1])\n",
    "    plt.plot(range(len(nn_model_result[1])), nn_model_result[1])\n",
    "    # axis labels\n",
    "    plt.xlabel('Iteration Step')\n",
    "    plt.ylabel('Test Error')\n",
    "    plt.title(\"Model 1 - Hidden Layer - ReLU\")\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.show()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train MSE at step 0: 418851054.59765625\n",
      "Mean Train MSE at step 1: 272890442.6533203\n",
      "Mean Train MSE at step 2: 244765948.3935547\n",
      "Mean Train MSE at step 3: 233784022.09375\n",
      "Mean Train MSE at step 4: 233537235.47070312\n",
      "Mean Train MSE at step 5: 230197996.39257812\n",
      "Mean Train MSE at step 6: 229449479.65820312\n",
      "Mean Train MSE at step 7: 221360777.2373047\n",
      "Mean Train MSE at step 8: 218563518.53515625\n",
      "Mean Train MSE at step 9: 218736194.40234375\n",
      "Mean Train MSE at step 10: 218161342.54296875\n",
      "Mean Train MSE at step 11: 217169647.82421875\n",
      "Mean Train MSE at step 12: 214832262.9033203\n",
      "Mean Train MSE at step 13: 213844315.00195312\n",
      "Mean Train MSE at step 14: 213265886.2109375\n",
      "Mean Train MSE at step 15: 212003758.7109375\n",
      "Mean Train MSE at step 16: 213679014.5419922\n",
      "Mean Train MSE at step 17: 213617214.11132812\n",
      "Mean Train MSE at step 18: 210267108.1953125\n",
      "Mean Train MSE at step 19: 211717567.40820312\n",
      "Mean Train MSE at step 20: 211846733.7373047\n",
      "Mean Train MSE at step 21: 207780717.89257812\n",
      "Mean Train MSE at step 22: 205139230.5546875\n",
      "Mean Train MSE at step 23: 204666548.92578125\n",
      "Mean Train MSE at step 24: 210712419.43359375\n",
      "Mean Train MSE at step 25: 208496650.796875\n",
      "Mean Train MSE at step 26: 205212202.59375\n",
      "Mean Train MSE at step 27: 204115665.56054688\n",
      "Mean Train MSE at step 28: 203205474.06445312\n",
      "Mean Train MSE at step 29: 202872203.32421875\n",
      "Mean Train MSE at step 30: 200160339.00878906\n",
      "Mean Train MSE at step 31: 200419947.60742188\n",
      "Mean Train MSE at step 32: 199292697.61816406\n",
      "Mean Train MSE at step 33: 201437500.0546875\n",
      "Mean Train MSE at step 34: 197905944.11914062\n",
      "Mean Train MSE at step 35: 197590506.74804688\n",
      "Mean Train MSE at step 36: 196414045.24316406\n",
      "Mean Train MSE at step 37: 195248200.03515625\n",
      "Mean Train MSE at step 38: 196100694.671875\n",
      "Mean Train MSE at step 39: 195707371.046875\n",
      "Mean Train MSE at step 40: 195645581.11914062\n",
      "Mean Train MSE at step 41: 192881074.93066406\n",
      "Mean Train MSE at step 42: 192193322.41308594\n",
      "Mean Train MSE at step 43: 191581642.87695312\n",
      "Mean Train MSE at step 44: 193964370.2578125\n",
      "Mean Train MSE at step 45: 191665806.74804688\n",
      "Mean Train MSE at step 46: 191060248.25\n",
      "Mean Train MSE at step 47: 189839434.40625\n",
      "Mean Train MSE at step 48: 189797480.35546875\n",
      "Mean Train MSE at step 49: 192798881.24609375\n",
      "nan\n",
      "Train MSE for model, dim = 8 is: (346756.5625, 0.7067438177730934) Train R-squared is: 0.7067438177730934\n",
      "Test MSE for model, dim = 8 is: 305637.1875 Test R-squared is: 0.7261011624615954\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
