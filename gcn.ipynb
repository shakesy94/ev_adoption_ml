{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1f20af8-74e6-40a0-9e2c-42906f1613db",
   "metadata": {},
   "source": [
    "# GNN \n",
    "\n",
    "\n",
    "Code based on \n",
    "\n",
    "https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing#scrollTo=zF5bw3m9UrMy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a971f309-cb9a-45f2-b697-74d55f2e3bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\markm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import random\n",
    "from math import floor\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f79c5f-51de-4652-8cac-01edefedc990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1250])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "X = pd.read_csv('./Data/df_X_gnn.csv')\n",
    "y = pd.read_csv('./Data/df_y_gnn.csv')\n",
    "edge_idx = pd.read_csv('./Data/df_e_idx_gnn.csv')\n",
    "\n",
    "edge_att = pd.read_csv('./Data/df_e_att_gnn.csv')\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).float()\n",
    "edge_idx = torch.tensor(edge_idx.to_numpy()).int()\n",
    "edge_att = torch.tensor(edge_att.to_numpy()).float()\n",
    "\n",
    "#edge_idx = edge_idx.transpose(0,1)\n",
    "\n",
    "edge_idx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f466c9-6b24-407d-a1f8-b2a0004974d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make masks\n",
    "n = X.shape[0]\n",
    "randomassort = list(range(n))\n",
    "random.shuffle(randomassort)\n",
    "\n",
    "# percentage of training mask\n",
    "train_perc = 0.1\n",
    "max_train = floor(len(randomassort) * train_perc)\n",
    "train_mask_idx = torch.tensor(randomassort[:max_train])\n",
    "test_mask_idx = torch.tensor(randomassort[max_train:])\n",
    "train_mask = torch.zeros(n); test_mask = torch.zeros(n)\n",
    "train_mask.scatter_(0, train_mask_idx, 1)\n",
    "test_mask.scatter_(0, test_mask_idx, 1)\n",
    "train_mask = train_mask.type(torch.bool)\n",
    "test_mask = test_mask.type(torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6e0485-3bbd-4f3a-9b6b-5551218b185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[297, 10], edge_index=[2, 1250], y=[297, 2], test_mask=[297], train_mask=[297])\n",
      "==============================================================\n",
      "Number of nodes: 297\n",
      "Number of edges: 1250\n",
      "Average node degree: 4.21\n",
      "Number of training nodes: 29\n",
      "Training node label rate: 0.10\n",
      "Has isolated nodes: True\n"
     ]
    }
   ],
   "source": [
    "data = Data(x = X, y = y, edge_index = edge_idx)#, edge_attr = edge_att)\n",
    "\n",
    "data.test_mask = test_mask\n",
    "data.train_mask = train_mask\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3279d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.6059e+04, 4.1172e+04, 5.0984e+05,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [5.6059e+04, 4.1172e+04, 6.4998e+05,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [5.6059e+04, 4.1172e+04, 1.3588e+04,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [5.6059e+04, 4.1172e+04, 4.1386e+04,  ..., 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [5.6059e+04, 4.1172e+04, 4.9018e+04,  ..., 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [5.6059e+04, 4.1172e+04, 3.5275e+04,  ..., 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5691920a-d1b3-4834-ac10-7a0573119d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, with_labels=False)#, pos=nx.spring_layout(G, seed=42)),\n",
    "                     #node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "visualize_graph(G, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003ed154-b439-4cec-afc4-146a83061332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(10, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 2)\n",
      "  (pred): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(data.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.pred = Linear(2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.pred(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da0b4f4-7a36-452a-98b4-eb7bb946041d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(3179591.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3179591.7500, grad_fn=<MseLossBackward0>)\n",
      "1 tensor(3179585.7500, grad_fn=<MseLossBackward0>)\n",
      "2 tensor(3179579., grad_fn=<MseLossBackward0>)\n",
      "3 tensor(3179572.7500, grad_fn=<MseLossBackward0>)\n",
      "4 tensor(3179566.5000, grad_fn=<MseLossBackward0>)\n",
      "5 tensor(3179560.5000, grad_fn=<MseLossBackward0>)\n",
      "6 tensor(3179554.5000, grad_fn=<MseLossBackward0>)\n",
      "7 tensor(3179548.2500, grad_fn=<MseLossBackward0>)\n",
      "8 tensor(3179542.2500, grad_fn=<MseLossBackward0>)\n",
      "9 tensor(3179536.2500, grad_fn=<MseLossBackward0>)\n",
      "10 tensor(3179530.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3179530.2500, grad_fn=<MseLossBackward0>)\n",
      "11 tensor(3179524.2500, grad_fn=<MseLossBackward0>)\n",
      "12 tensor(3179517.5000, grad_fn=<MseLossBackward0>)\n",
      "13 tensor(3179512., grad_fn=<MseLossBackward0>)\n",
      "14 tensor(3179505.7500, grad_fn=<MseLossBackward0>)\n",
      "15 tensor(3179499.7500, grad_fn=<MseLossBackward0>)\n",
      "16 tensor(3179493.5000, grad_fn=<MseLossBackward0>)\n",
      "17 tensor(3179487.7500, grad_fn=<MseLossBackward0>)\n",
      "18 tensor(3179482., grad_fn=<MseLossBackward0>)\n",
      "19 tensor(3179475.5000, grad_fn=<MseLossBackward0>)\n",
      "20 tensor(3179469.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3179469.2500, grad_fn=<MseLossBackward0>)\n",
      "21 tensor(3179463.2500, grad_fn=<MseLossBackward0>)\n",
      "22 tensor(3179457.7500, grad_fn=<MseLossBackward0>)\n",
      "23 tensor(3179451.2500, grad_fn=<MseLossBackward0>)\n",
      "24 tensor(3179445.7500, grad_fn=<MseLossBackward0>)\n",
      "25 tensor(3179439.2500, grad_fn=<MseLossBackward0>)\n",
      "26 tensor(3179433.5000, grad_fn=<MseLossBackward0>)\n",
      "27 tensor(3179427.5000, grad_fn=<MseLossBackward0>)\n",
      "28 tensor(3179421.7500, grad_fn=<MseLossBackward0>)\n",
      "29 tensor(3179415.7500, grad_fn=<MseLossBackward0>)\n",
      "30 tensor(3179410., grad_fn=<MseLossBackward0>)\n",
      "tensor(3179410., grad_fn=<MseLossBackward0>)\n",
      "31 tensor(3179403.5000, grad_fn=<MseLossBackward0>)\n",
      "32 tensor(3179397.7500, grad_fn=<MseLossBackward0>)\n",
      "33 tensor(3179392., grad_fn=<MseLossBackward0>)\n",
      "34 tensor(3179386., grad_fn=<MseLossBackward0>)\n",
      "35 tensor(3179379.5000, grad_fn=<MseLossBackward0>)\n",
      "36 tensor(3179374., grad_fn=<MseLossBackward0>)\n",
      "37 tensor(3179368., grad_fn=<MseLossBackward0>)\n",
      "38 tensor(3179362., grad_fn=<MseLossBackward0>)\n",
      "39 tensor(3179355.7500, grad_fn=<MseLossBackward0>)\n",
      "40 tensor(3179350., grad_fn=<MseLossBackward0>)\n",
      "tensor(3179350., grad_fn=<MseLossBackward0>)\n",
      "41 tensor(3179343.7500, grad_fn=<MseLossBackward0>)\n",
      "42 tensor(3179338., grad_fn=<MseLossBackward0>)\n",
      "43 tensor(3179332.5000, grad_fn=<MseLossBackward0>)\n",
      "44 tensor(3179326., grad_fn=<MseLossBackward0>)\n",
      "45 tensor(3179320.2500, grad_fn=<MseLossBackward0>)\n",
      "46 tensor(3179314., grad_fn=<MseLossBackward0>)\n",
      "47 tensor(3179307.7500, grad_fn=<MseLossBackward0>)\n",
      "48 tensor(3179302., grad_fn=<MseLossBackward0>)\n",
      "49 tensor(3179295.7500, grad_fn=<MseLossBackward0>)\n",
      "50 tensor(3179290., grad_fn=<MseLossBackward0>)\n",
      "tensor(3179290., grad_fn=<MseLossBackward0>)\n",
      "51 tensor(3179283.7500, grad_fn=<MseLossBackward0>)\n",
      "52 tensor(3179277.7500, grad_fn=<MseLossBackward0>)\n",
      "53 tensor(3179271.5000, grad_fn=<MseLossBackward0>)\n",
      "54 tensor(3179265.7500, grad_fn=<MseLossBackward0>)\n",
      "55 tensor(3179259.5000, grad_fn=<MseLossBackward0>)\n",
      "56 tensor(3179253.2500, grad_fn=<MseLossBackward0>)\n",
      "57 tensor(3179247.2500, grad_fn=<MseLossBackward0>)\n",
      "58 tensor(3179241., grad_fn=<MseLossBackward0>)\n",
      "59 tensor(3179235., grad_fn=<MseLossBackward0>)\n",
      "60 tensor(3179229., grad_fn=<MseLossBackward0>)\n",
      "tensor(3179229., grad_fn=<MseLossBackward0>)\n",
      "61 tensor(3179223.2500, grad_fn=<MseLossBackward0>)\n",
      "62 tensor(3179216.7500, grad_fn=<MseLossBackward0>)\n",
      "63 tensor(3179211., grad_fn=<MseLossBackward0>)\n",
      "64 tensor(3179204.7500, grad_fn=<MseLossBackward0>)\n",
      "65 tensor(3179199., grad_fn=<MseLossBackward0>)\n",
      "66 tensor(3179192.5000, grad_fn=<MseLossBackward0>)\n",
      "67 tensor(3179186.5000, grad_fn=<MseLossBackward0>)\n",
      "68 tensor(3179180.5000, grad_fn=<MseLossBackward0>)\n",
      "69 tensor(3179174., grad_fn=<MseLossBackward0>)\n",
      "70 tensor(3179168.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3179168.2500, grad_fn=<MseLossBackward0>)\n",
      "71 tensor(3179162., grad_fn=<MseLossBackward0>)\n",
      "72 tensor(3179155.7500, grad_fn=<MseLossBackward0>)\n",
      "73 tensor(3179149.7500, grad_fn=<MseLossBackward0>)\n",
      "74 tensor(3179143.7500, grad_fn=<MseLossBackward0>)\n",
      "75 tensor(3179137.7500, grad_fn=<MseLossBackward0>)\n",
      "76 tensor(3179131.5000, grad_fn=<MseLossBackward0>)\n",
      "77 tensor(3179125.2500, grad_fn=<MseLossBackward0>)\n",
      "78 tensor(3179119.5000, grad_fn=<MseLossBackward0>)\n",
      "79 tensor(3179113., grad_fn=<MseLossBackward0>)\n",
      "80 tensor(3179107., grad_fn=<MseLossBackward0>)\n",
      "tensor(3179107., grad_fn=<MseLossBackward0>)\n",
      "81 tensor(3179101., grad_fn=<MseLossBackward0>)\n",
      "82 tensor(3179094.5000, grad_fn=<MseLossBackward0>)\n",
      "83 tensor(3179088.7500, grad_fn=<MseLossBackward0>)\n",
      "84 tensor(3179082.2500, grad_fn=<MseLossBackward0>)\n",
      "85 tensor(3179076.5000, grad_fn=<MseLossBackward0>)\n",
      "86 tensor(3179070.2500, grad_fn=<MseLossBackward0>)\n",
      "87 tensor(3179064.2500, grad_fn=<MseLossBackward0>)\n",
      "88 tensor(3179058.2500, grad_fn=<MseLossBackward0>)\n",
      "89 tensor(3179051.7500, grad_fn=<MseLossBackward0>)\n",
      "90 tensor(3179045.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3179045.7500, grad_fn=<MseLossBackward0>)\n",
      "91 tensor(3179039.7500, grad_fn=<MseLossBackward0>)\n",
      "92 tensor(3179034., grad_fn=<MseLossBackward0>)\n",
      "93 tensor(3179027.5000, grad_fn=<MseLossBackward0>)\n",
      "94 tensor(3179021.7500, grad_fn=<MseLossBackward0>)\n",
      "95 tensor(3179015.5000, grad_fn=<MseLossBackward0>)\n",
      "96 tensor(3179009.7500, grad_fn=<MseLossBackward0>)\n",
      "97 tensor(3179003.2500, grad_fn=<MseLossBackward0>)\n",
      "98 tensor(3178997.2500, grad_fn=<MseLossBackward0>)\n",
      "99 tensor(3178991.2500, grad_fn=<MseLossBackward0>)\n",
      "100 tensor(3178984.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178984.7500, grad_fn=<MseLossBackward0>)\n",
      "101 tensor(3178979.2500, grad_fn=<MseLossBackward0>)\n",
      "102 tensor(3178973.2500, grad_fn=<MseLossBackward0>)\n",
      "103 tensor(3178967.2500, grad_fn=<MseLossBackward0>)\n",
      "104 tensor(3178960.7500, grad_fn=<MseLossBackward0>)\n",
      "105 tensor(3178954.7500, grad_fn=<MseLossBackward0>)\n",
      "106 tensor(3178948.7500, grad_fn=<MseLossBackward0>)\n",
      "107 tensor(3178943., grad_fn=<MseLossBackward0>)\n",
      "108 tensor(3178936.7500, grad_fn=<MseLossBackward0>)\n",
      "109 tensor(3178931., grad_fn=<MseLossBackward0>)\n",
      "110 tensor(3178924.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178924.7500, grad_fn=<MseLossBackward0>)\n",
      "111 tensor(3178918.5000, grad_fn=<MseLossBackward0>)\n",
      "112 tensor(3178912.7500, grad_fn=<MseLossBackward0>)\n",
      "113 tensor(3178906.7500, grad_fn=<MseLossBackward0>)\n",
      "114 tensor(3178900.7500, grad_fn=<MseLossBackward0>)\n",
      "115 tensor(3178894.5000, grad_fn=<MseLossBackward0>)\n",
      "116 tensor(3178888.7500, grad_fn=<MseLossBackward0>)\n",
      "117 tensor(3178883., grad_fn=<MseLossBackward0>)\n",
      "118 tensor(3178877., grad_fn=<MseLossBackward0>)\n",
      "119 tensor(3178871., grad_fn=<MseLossBackward0>)\n",
      "120 tensor(3178864.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178864.7500, grad_fn=<MseLossBackward0>)\n",
      "121 tensor(3178859., grad_fn=<MseLossBackward0>)\n",
      "122 tensor(3178853.2500, grad_fn=<MseLossBackward0>)\n",
      "123 tensor(3178847., grad_fn=<MseLossBackward0>)\n",
      "124 tensor(3178841., grad_fn=<MseLossBackward0>)\n",
      "125 tensor(3178835., grad_fn=<MseLossBackward0>)\n",
      "126 tensor(3178829.2500, grad_fn=<MseLossBackward0>)\n",
      "127 tensor(3178823.5000, grad_fn=<MseLossBackward0>)\n",
      "128 tensor(3178817.5000, grad_fn=<MseLossBackward0>)\n",
      "129 tensor(3178811.5000, grad_fn=<MseLossBackward0>)\n",
      "130 tensor(3178806., grad_fn=<MseLossBackward0>)\n",
      "tensor(3178806., grad_fn=<MseLossBackward0>)\n",
      "131 tensor(3178800.2500, grad_fn=<MseLossBackward0>)\n",
      "132 tensor(3178794.5000, grad_fn=<MseLossBackward0>)\n",
      "133 tensor(3178788.7500, grad_fn=<MseLossBackward0>)\n",
      "134 tensor(3178783., grad_fn=<MseLossBackward0>)\n",
      "135 tensor(3178776.5000, grad_fn=<MseLossBackward0>)\n",
      "136 tensor(3178771., grad_fn=<MseLossBackward0>)\n",
      "137 tensor(3178765., grad_fn=<MseLossBackward0>)\n",
      "138 tensor(3178759.2500, grad_fn=<MseLossBackward0>)\n",
      "139 tensor(3178753.5000, grad_fn=<MseLossBackward0>)\n",
      "140 tensor(3178747.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178747.2500, grad_fn=<MseLossBackward0>)\n",
      "141 tensor(3178741.7500, grad_fn=<MseLossBackward0>)\n",
      "142 tensor(3178736., grad_fn=<MseLossBackward0>)\n",
      "143 tensor(3178730., grad_fn=<MseLossBackward0>)\n",
      "144 tensor(3178724.5000, grad_fn=<MseLossBackward0>)\n",
      "145 tensor(3178719., grad_fn=<MseLossBackward0>)\n",
      "146 tensor(3178713., grad_fn=<MseLossBackward0>)\n",
      "147 tensor(3178707.2500, grad_fn=<MseLossBackward0>)\n",
      "148 tensor(3178701.2500, grad_fn=<MseLossBackward0>)\n",
      "149 tensor(3178695.5000, grad_fn=<MseLossBackward0>)\n",
      "150 tensor(3178690.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178690.2500, grad_fn=<MseLossBackward0>)\n",
      "151 tensor(3178684.2500, grad_fn=<MseLossBackward0>)\n",
      "152 tensor(3178678.5000, grad_fn=<MseLossBackward0>)\n",
      "153 tensor(3178673., grad_fn=<MseLossBackward0>)\n",
      "154 tensor(3178667., grad_fn=<MseLossBackward0>)\n",
      "155 tensor(3178661.2500, grad_fn=<MseLossBackward0>)\n",
      "156 tensor(3178655.2500, grad_fn=<MseLossBackward0>)\n",
      "157 tensor(3178649.7500, grad_fn=<MseLossBackward0>)\n",
      "158 tensor(3178644.2500, grad_fn=<MseLossBackward0>)\n",
      "159 tensor(3178638.5000, grad_fn=<MseLossBackward0>)\n",
      "160 tensor(3178633., grad_fn=<MseLossBackward0>)\n",
      "tensor(3178633., grad_fn=<MseLossBackward0>)\n",
      "161 tensor(3178627.2500, grad_fn=<MseLossBackward0>)\n",
      "162 tensor(3178621.2500, grad_fn=<MseLossBackward0>)\n",
      "163 tensor(3178616., grad_fn=<MseLossBackward0>)\n",
      "164 tensor(3178610.5000, grad_fn=<MseLossBackward0>)\n",
      "165 tensor(3178604.7500, grad_fn=<MseLossBackward0>)\n",
      "166 tensor(3178599.2500, grad_fn=<MseLossBackward0>)\n",
      "167 tensor(3178593.7500, grad_fn=<MseLossBackward0>)\n",
      "168 tensor(3178588.2500, grad_fn=<MseLossBackward0>)\n",
      "169 tensor(3178582.5000, grad_fn=<MseLossBackward0>)\n",
      "170 tensor(3178577., grad_fn=<MseLossBackward0>)\n",
      "tensor(3178577., grad_fn=<MseLossBackward0>)\n",
      "171 tensor(3178571.5000, grad_fn=<MseLossBackward0>)\n",
      "172 tensor(3178566., grad_fn=<MseLossBackward0>)\n",
      "173 tensor(3178560., grad_fn=<MseLossBackward0>)\n",
      "174 tensor(3178554.7500, grad_fn=<MseLossBackward0>)\n",
      "175 tensor(3178549., grad_fn=<MseLossBackward0>)\n",
      "176 tensor(3178543.7500, grad_fn=<MseLossBackward0>)\n",
      "177 tensor(3178538.2500, grad_fn=<MseLossBackward0>)\n",
      "178 tensor(3178532.5000, grad_fn=<MseLossBackward0>)\n",
      "179 tensor(3178527., grad_fn=<MseLossBackward0>)\n",
      "180 tensor(3178521.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178521.7500, grad_fn=<MseLossBackward0>)\n",
      "181 tensor(3178516.2500, grad_fn=<MseLossBackward0>)\n",
      "182 tensor(3178511., grad_fn=<MseLossBackward0>)\n",
      "183 tensor(3178505., grad_fn=<MseLossBackward0>)\n",
      "184 tensor(3178499.5000, grad_fn=<MseLossBackward0>)\n",
      "185 tensor(3178494., grad_fn=<MseLossBackward0>)\n",
      "186 tensor(3178488.5000, grad_fn=<MseLossBackward0>)\n",
      "187 tensor(3178483.2500, grad_fn=<MseLossBackward0>)\n",
      "188 tensor(3178477.5000, grad_fn=<MseLossBackward0>)\n",
      "189 tensor(3178472.2500, grad_fn=<MseLossBackward0>)\n",
      "190 tensor(3178466.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178466.5000, grad_fn=<MseLossBackward0>)\n",
      "191 tensor(3178461.2500, grad_fn=<MseLossBackward0>)\n",
      "192 tensor(3178455.7500, grad_fn=<MseLossBackward0>)\n",
      "193 tensor(3178450.5000, grad_fn=<MseLossBackward0>)\n",
      "194 tensor(3178445.2500, grad_fn=<MseLossBackward0>)\n",
      "195 tensor(3178439.7500, grad_fn=<MseLossBackward0>)\n",
      "196 tensor(3178434.2500, grad_fn=<MseLossBackward0>)\n",
      "197 tensor(3178428.7500, grad_fn=<MseLossBackward0>)\n",
      "198 tensor(3178423.2500, grad_fn=<MseLossBackward0>)\n",
      "199 tensor(3178418.2500, grad_fn=<MseLossBackward0>)\n",
      "200 tensor(3178412.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178412.5000, grad_fn=<MseLossBackward0>)\n",
      "201 tensor(3178407., grad_fn=<MseLossBackward0>)\n",
      "202 tensor(3178402., grad_fn=<MseLossBackward0>)\n",
      "203 tensor(3178396.7500, grad_fn=<MseLossBackward0>)\n",
      "204 tensor(3178391.5000, grad_fn=<MseLossBackward0>)\n",
      "205 tensor(3178386., grad_fn=<MseLossBackward0>)\n",
      "206 tensor(3178380.7500, grad_fn=<MseLossBackward0>)\n",
      "207 tensor(3178375.5000, grad_fn=<MseLossBackward0>)\n",
      "208 tensor(3178369.7500, grad_fn=<MseLossBackward0>)\n",
      "209 tensor(3178364.5000, grad_fn=<MseLossBackward0>)\n",
      "210 tensor(3178359.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178359.2500, grad_fn=<MseLossBackward0>)\n",
      "211 tensor(3178353.7500, grad_fn=<MseLossBackward0>)\n",
      "212 tensor(3178349., grad_fn=<MseLossBackward0>)\n",
      "213 tensor(3178343.5000, grad_fn=<MseLossBackward0>)\n",
      "214 tensor(3178338.2500, grad_fn=<MseLossBackward0>)\n",
      "215 tensor(3178332.7500, grad_fn=<MseLossBackward0>)\n",
      "216 tensor(3178327.5000, grad_fn=<MseLossBackward0>)\n",
      "217 tensor(3178322., grad_fn=<MseLossBackward0>)\n",
      "218 tensor(3178316.7500, grad_fn=<MseLossBackward0>)\n",
      "219 tensor(3178311.5000, grad_fn=<MseLossBackward0>)\n",
      "220 tensor(3178306.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178306.5000, grad_fn=<MseLossBackward0>)\n",
      "221 tensor(3178301.2500, grad_fn=<MseLossBackward0>)\n",
      "222 tensor(3178295.7500, grad_fn=<MseLossBackward0>)\n",
      "223 tensor(3178290.7500, grad_fn=<MseLossBackward0>)\n",
      "224 tensor(3178285.2500, grad_fn=<MseLossBackward0>)\n",
      "225 tensor(3178280.2500, grad_fn=<MseLossBackward0>)\n",
      "226 tensor(3178275., grad_fn=<MseLossBackward0>)\n",
      "227 tensor(3178269.5000, grad_fn=<MseLossBackward0>)\n",
      "228 tensor(3178264.7500, grad_fn=<MseLossBackward0>)\n",
      "229 tensor(3178259., grad_fn=<MseLossBackward0>)\n",
      "230 tensor(3178253.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178253.7500, grad_fn=<MseLossBackward0>)\n",
      "231 tensor(3178248.7500, grad_fn=<MseLossBackward0>)\n",
      "232 tensor(3178243.5000, grad_fn=<MseLossBackward0>)\n",
      "233 tensor(3178238.2500, grad_fn=<MseLossBackward0>)\n",
      "234 tensor(3178233., grad_fn=<MseLossBackward0>)\n",
      "235 tensor(3178227.7500, grad_fn=<MseLossBackward0>)\n",
      "236 tensor(3178223.2500, grad_fn=<MseLossBackward0>)\n",
      "237 tensor(3178218., grad_fn=<MseLossBackward0>)\n",
      "238 tensor(3178212.7500, grad_fn=<MseLossBackward0>)\n",
      "239 tensor(3178207.5000, grad_fn=<MseLossBackward0>)\n",
      "240 tensor(3178202., grad_fn=<MseLossBackward0>)\n",
      "tensor(3178202., grad_fn=<MseLossBackward0>)\n",
      "241 tensor(3178197., grad_fn=<MseLossBackward0>)\n",
      "242 tensor(3178192.2500, grad_fn=<MseLossBackward0>)\n",
      "243 tensor(3178186.7500, grad_fn=<MseLossBackward0>)\n",
      "244 tensor(3178181.2500, grad_fn=<MseLossBackward0>)\n",
      "245 tensor(3178176.5000, grad_fn=<MseLossBackward0>)\n",
      "246 tensor(3178171.5000, grad_fn=<MseLossBackward0>)\n",
      "247 tensor(3178166., grad_fn=<MseLossBackward0>)\n",
      "248 tensor(3178160.7500, grad_fn=<MseLossBackward0>)\n",
      "249 tensor(3178155.7500, grad_fn=<MseLossBackward0>)\n",
      "250 tensor(3178151., grad_fn=<MseLossBackward0>)\n",
      "tensor(3178151., grad_fn=<MseLossBackward0>)\n",
      "251 tensor(3178145.7500, grad_fn=<MseLossBackward0>)\n",
      "252 tensor(3178140.5000, grad_fn=<MseLossBackward0>)\n",
      "253 tensor(3178135.2500, grad_fn=<MseLossBackward0>)\n",
      "254 tensor(3178130.2500, grad_fn=<MseLossBackward0>)\n",
      "255 tensor(3178125.2500, grad_fn=<MseLossBackward0>)\n",
      "256 tensor(3178120.2500, grad_fn=<MseLossBackward0>)\n",
      "257 tensor(3178115., grad_fn=<MseLossBackward0>)\n",
      "258 tensor(3178110., grad_fn=<MseLossBackward0>)\n",
      "259 tensor(3178104.7500, grad_fn=<MseLossBackward0>)\n",
      "260 tensor(3178099.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3178099.2500, grad_fn=<MseLossBackward0>)\n",
      "261 tensor(3178094.2500, grad_fn=<MseLossBackward0>)\n",
      "262 tensor(3178090., grad_fn=<MseLossBackward0>)\n",
      "263 tensor(3178084.5000, grad_fn=<MseLossBackward0>)\n",
      "264 tensor(3178079.5000, grad_fn=<MseLossBackward0>)\n",
      "265 tensor(3178074.7500, grad_fn=<MseLossBackward0>)\n",
      "266 tensor(3178069.2500, grad_fn=<MseLossBackward0>)\n",
      "267 tensor(3178064.2500, grad_fn=<MseLossBackward0>)\n",
      "268 tensor(3178059., grad_fn=<MseLossBackward0>)\n",
      "269 tensor(3178054., grad_fn=<MseLossBackward0>)\n",
      "270 tensor(3178049., grad_fn=<MseLossBackward0>)\n",
      "tensor(3178049., grad_fn=<MseLossBackward0>)\n",
      "271 tensor(3178043.7500, grad_fn=<MseLossBackward0>)\n",
      "272 tensor(3178039., grad_fn=<MseLossBackward0>)\n",
      "273 tensor(3178034., grad_fn=<MseLossBackward0>)\n",
      "274 tensor(3178029.2500, grad_fn=<MseLossBackward0>)\n",
      "275 tensor(3178023.7500, grad_fn=<MseLossBackward0>)\n",
      "276 tensor(3178018.7500, grad_fn=<MseLossBackward0>)\n",
      "277 tensor(3178013.7500, grad_fn=<MseLossBackward0>)\n",
      "278 tensor(3178008.5000, grad_fn=<MseLossBackward0>)\n",
      "279 tensor(3178004.2500, grad_fn=<MseLossBackward0>)\n",
      "280 tensor(3177999., grad_fn=<MseLossBackward0>)\n",
      "tensor(3177999., grad_fn=<MseLossBackward0>)\n",
      "281 tensor(3177994., grad_fn=<MseLossBackward0>)\n",
      "282 tensor(3177988.5000, grad_fn=<MseLossBackward0>)\n",
      "283 tensor(3177983.7500, grad_fn=<MseLossBackward0>)\n",
      "284 tensor(3177978.5000, grad_fn=<MseLossBackward0>)\n",
      "285 tensor(3177973.7500, grad_fn=<MseLossBackward0>)\n",
      "286 tensor(3177968.7500, grad_fn=<MseLossBackward0>)\n",
      "287 tensor(3177963.7500, grad_fn=<MseLossBackward0>)\n",
      "288 tensor(3177958.5000, grad_fn=<MseLossBackward0>)\n",
      "289 tensor(3177953.7500, grad_fn=<MseLossBackward0>)\n",
      "290 tensor(3177948.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177948.7500, grad_fn=<MseLossBackward0>)\n",
      "291 tensor(3177943.7500, grad_fn=<MseLossBackward0>)\n",
      "292 tensor(3177938.7500, grad_fn=<MseLossBackward0>)\n",
      "293 tensor(3177933.7500, grad_fn=<MseLossBackward0>)\n",
      "294 tensor(3177928.7500, grad_fn=<MseLossBackward0>)\n",
      "295 tensor(3177923.7500, grad_fn=<MseLossBackward0>)\n",
      "296 tensor(3177919.2500, grad_fn=<MseLossBackward0>)\n",
      "297 tensor(3177914., grad_fn=<MseLossBackward0>)\n",
      "298 tensor(3177909., grad_fn=<MseLossBackward0>)\n",
      "299 tensor(3177904., grad_fn=<MseLossBackward0>)\n",
      "300 tensor(3177899., grad_fn=<MseLossBackward0>)\n",
      "tensor(3177899., grad_fn=<MseLossBackward0>)\n",
      "301 tensor(3177894.5000, grad_fn=<MseLossBackward0>)\n",
      "302 tensor(3177889.5000, grad_fn=<MseLossBackward0>)\n",
      "303 tensor(3177884.2500, grad_fn=<MseLossBackward0>)\n",
      "304 tensor(3177879.5000, grad_fn=<MseLossBackward0>)\n",
      "305 tensor(3177874.2500, grad_fn=<MseLossBackward0>)\n",
      "306 tensor(3177869.5000, grad_fn=<MseLossBackward0>)\n",
      "307 tensor(3177864.7500, grad_fn=<MseLossBackward0>)\n",
      "308 tensor(3177859.5000, grad_fn=<MseLossBackward0>)\n",
      "309 tensor(3177855., grad_fn=<MseLossBackward0>)\n",
      "310 tensor(3177850., grad_fn=<MseLossBackward0>)\n",
      "tensor(3177850., grad_fn=<MseLossBackward0>)\n",
      "311 tensor(3177845., grad_fn=<MseLossBackward0>)\n",
      "312 tensor(3177840., grad_fn=<MseLossBackward0>)\n",
      "313 tensor(3177835.2500, grad_fn=<MseLossBackward0>)\n",
      "314 tensor(3177830., grad_fn=<MseLossBackward0>)\n",
      "315 tensor(3177825.5000, grad_fn=<MseLossBackward0>)\n",
      "316 tensor(3177820.5000, grad_fn=<MseLossBackward0>)\n",
      "317 tensor(3177815.2500, grad_fn=<MseLossBackward0>)\n",
      "318 tensor(3177810.7500, grad_fn=<MseLossBackward0>)\n",
      "319 tensor(3177805.7500, grad_fn=<MseLossBackward0>)\n",
      "320 tensor(3177801., grad_fn=<MseLossBackward0>)\n",
      "tensor(3177801., grad_fn=<MseLossBackward0>)\n",
      "321 tensor(3177795.7500, grad_fn=<MseLossBackward0>)\n",
      "322 tensor(3177791.2500, grad_fn=<MseLossBackward0>)\n",
      "323 tensor(3177786.2500, grad_fn=<MseLossBackward0>)\n",
      "324 tensor(3177781., grad_fn=<MseLossBackward0>)\n",
      "325 tensor(3177776.2500, grad_fn=<MseLossBackward0>)\n",
      "326 tensor(3177771.7500, grad_fn=<MseLossBackward0>)\n",
      "327 tensor(3177766.5000, grad_fn=<MseLossBackward0>)\n",
      "328 tensor(3177762., grad_fn=<MseLossBackward0>)\n",
      "329 tensor(3177756.7500, grad_fn=<MseLossBackward0>)\n",
      "330 tensor(3177751.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177751.7500, grad_fn=<MseLossBackward0>)\n",
      "331 tensor(3177747.2500, grad_fn=<MseLossBackward0>)\n",
      "332 tensor(3177742.2500, grad_fn=<MseLossBackward0>)\n",
      "333 tensor(3177737.7500, grad_fn=<MseLossBackward0>)\n",
      "334 tensor(3177732.7500, grad_fn=<MseLossBackward0>)\n",
      "335 tensor(3177727.5000, grad_fn=<MseLossBackward0>)\n",
      "336 tensor(3177723.2500, grad_fn=<MseLossBackward0>)\n",
      "337 tensor(3177718., grad_fn=<MseLossBackward0>)\n",
      "338 tensor(3177713.5000, grad_fn=<MseLossBackward0>)\n",
      "339 tensor(3177708.2500, grad_fn=<MseLossBackward0>)\n",
      "340 tensor(3177703.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177703.2500, grad_fn=<MseLossBackward0>)\n",
      "341 tensor(3177698.7500, grad_fn=<MseLossBackward0>)\n",
      "342 tensor(3177693.7500, grad_fn=<MseLossBackward0>)\n",
      "343 tensor(3177689., grad_fn=<MseLossBackward0>)\n",
      "344 tensor(3177684.2500, grad_fn=<MseLossBackward0>)\n",
      "345 tensor(3177679.5000, grad_fn=<MseLossBackward0>)\n",
      "346 tensor(3177674.7500, grad_fn=<MseLossBackward0>)\n",
      "347 tensor(3177670., grad_fn=<MseLossBackward0>)\n",
      "348 tensor(3177665., grad_fn=<MseLossBackward0>)\n",
      "349 tensor(3177659.7500, grad_fn=<MseLossBackward0>)\n",
      "350 tensor(3177655.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177655.5000, grad_fn=<MseLossBackward0>)\n",
      "351 tensor(3177650.5000, grad_fn=<MseLossBackward0>)\n",
      "352 tensor(3177645.5000, grad_fn=<MseLossBackward0>)\n",
      "353 tensor(3177640.7500, grad_fn=<MseLossBackward0>)\n",
      "354 tensor(3177635.7500, grad_fn=<MseLossBackward0>)\n",
      "355 tensor(3177631.5000, grad_fn=<MseLossBackward0>)\n",
      "356 tensor(3177626.5000, grad_fn=<MseLossBackward0>)\n",
      "357 tensor(3177621.7500, grad_fn=<MseLossBackward0>)\n",
      "358 tensor(3177616.7500, grad_fn=<MseLossBackward0>)\n",
      "359 tensor(3177612.5000, grad_fn=<MseLossBackward0>)\n",
      "360 tensor(3177607.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177607.5000, grad_fn=<MseLossBackward0>)\n",
      "361 tensor(3177602.5000, grad_fn=<MseLossBackward0>)\n",
      "362 tensor(3177597.5000, grad_fn=<MseLossBackward0>)\n",
      "363 tensor(3177592.7500, grad_fn=<MseLossBackward0>)\n",
      "364 tensor(3177588.5000, grad_fn=<MseLossBackward0>)\n",
      "365 tensor(3177583.2500, grad_fn=<MseLossBackward0>)\n",
      "366 tensor(3177578.7500, grad_fn=<MseLossBackward0>)\n",
      "367 tensor(3177573.5000, grad_fn=<MseLossBackward0>)\n",
      "368 tensor(3177569.5000, grad_fn=<MseLossBackward0>)\n",
      "369 tensor(3177564.5000, grad_fn=<MseLossBackward0>)\n",
      "370 tensor(3177559.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177559.5000, grad_fn=<MseLossBackward0>)\n",
      "371 tensor(3177554.7500, grad_fn=<MseLossBackward0>)\n",
      "372 tensor(3177549.7500, grad_fn=<MseLossBackward0>)\n",
      "373 tensor(3177545.7500, grad_fn=<MseLossBackward0>)\n",
      "374 tensor(3177540.5000, grad_fn=<MseLossBackward0>)\n",
      "375 tensor(3177535.7500, grad_fn=<MseLossBackward0>)\n",
      "376 tensor(3177530.7500, grad_fn=<MseLossBackward0>)\n",
      "377 tensor(3177526.2500, grad_fn=<MseLossBackward0>)\n",
      "378 tensor(3177521.5000, grad_fn=<MseLossBackward0>)\n",
      "379 tensor(3177517., grad_fn=<MseLossBackward0>)\n",
      "380 tensor(3177512., grad_fn=<MseLossBackward0>)\n",
      "tensor(3177512., grad_fn=<MseLossBackward0>)\n",
      "381 tensor(3177507.2500, grad_fn=<MseLossBackward0>)\n",
      "382 tensor(3177502.2500, grad_fn=<MseLossBackward0>)\n",
      "383 tensor(3177497.7500, grad_fn=<MseLossBackward0>)\n",
      "384 tensor(3177493.2500, grad_fn=<MseLossBackward0>)\n",
      "385 tensor(3177488., grad_fn=<MseLossBackward0>)\n",
      "386 tensor(3177483.5000, grad_fn=<MseLossBackward0>)\n",
      "387 tensor(3177478.5000, grad_fn=<MseLossBackward0>)\n",
      "388 tensor(3177474.2500, grad_fn=<MseLossBackward0>)\n",
      "389 tensor(3177469.2500, grad_fn=<MseLossBackward0>)\n",
      "390 tensor(3177464.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177464.7500, grad_fn=<MseLossBackward0>)\n",
      "391 tensor(3177459.7500, grad_fn=<MseLossBackward0>)\n",
      "392 tensor(3177455.2500, grad_fn=<MseLossBackward0>)\n",
      "393 tensor(3177450.2500, grad_fn=<MseLossBackward0>)\n",
      "394 tensor(3177446., grad_fn=<MseLossBackward0>)\n",
      "395 tensor(3177441., grad_fn=<MseLossBackward0>)\n",
      "396 tensor(3177436.5000, grad_fn=<MseLossBackward0>)\n",
      "397 tensor(3177431.7500, grad_fn=<MseLossBackward0>)\n",
      "398 tensor(3177427., grad_fn=<MseLossBackward0>)\n",
      "399 tensor(3177422., grad_fn=<MseLossBackward0>)\n",
      "400 tensor(3177417.5000, grad_fn=<MseLossBackward0>)\n",
      "tensor(3177417.5000, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GCN()\n",
    "\n",
    "criterion = torch.nn.MSELoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Define optimizer.\n",
    "\n",
    "\n",
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h\n",
    "\n",
    "for epoch in range(401):\n",
    "    \n",
    "    loss, h = train(data)\n",
    "    print(epoch, loss)\n",
    "    if epoch % 10 == 0:\n",
    "        #visualize_embedding(h, color=data.y, epoch=epoch, loss=loss)\n",
    "        print(loss)\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ff565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
